{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "\n",
    "# Reading CSV file\n",
    "def read_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Data from {file_path} loaded successfully!\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Reading Excel file\n",
    "def read_excel(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, engine='openpyxl')\n",
    "        print(f\"Data from {file_path} loaded successfully!\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Reading JSON file\n",
    "def read_json(file_path):\n",
    "    try:\n",
    "        df = pd.read_json(file_path)\n",
    "        print(f\"Data from {file_path} loaded successfully!\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Reading GeoJSON file\n",
    "def read_geojson(file_path):\n",
    "    try:\n",
    "        # First attempt: Try using geopandas\n",
    "        try:\n",
    "            gdf = gpd.read_file(file_path)\n",
    "            print(f\"Data from {file_path} loaded successfully using GeoPandas!\")\n",
    "            return gdf\n",
    "        except ImportError:\n",
    "            # If geopandas is not installed, fall back to manual JSON parsing\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                geojson_data = json.load(f)\n",
    "            \n",
    "            # Extract features and properties\n",
    "            features = []\n",
    "            for feature in geojson_data['features']:\n",
    "                # Get properties\n",
    "                properties = feature['properties']\n",
    "                \n",
    "                # Get geometry\n",
    "                geometry = feature['geometry']\n",
    "                \n",
    "                # Combine properties and geometry into one dictionary\n",
    "                feature_dict = {\n",
    "                    **properties,\n",
    "                    'geometry_type': geometry['type'],\n",
    "                    'coordinates': str(geometry['coordinates'])  # Convert to string to avoid nested structure\n",
    "                }\n",
    "                features.append(feature_dict)\n",
    "            \n",
    "            # Convert to pandas DataFrame\n",
    "            df = pd.DataFrame(features)\n",
    "            print(f\"Data from {file_path} loaded successfully using manual parsing!\")\n",
    "            return df\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Reading a dataset from any of these formats\n",
    "def read_dataset(file_path):\n",
    "    # Detect file extension to determine how to read it\n",
    "    if file_path.endswith('.csv'):\n",
    "        return read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        return read_excel(file_path)\n",
    "    elif file_path.endswith('.json'):\n",
    "        return read_json(file_path)\n",
    "    elif file_path.endswith('.geojson'):\n",
    "        return read_geojson(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file type\")\n",
    "        return None\n",
    "\n",
    "# Helper function to check if geopandas is installed\n",
    "def is_geopandas_available():\n",
    "    try:\n",
    "        import geopandas\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "# Helper function to install geopandas if needed\n",
    "def install_geopandas():\n",
    "    try:\n",
    "        import subprocess\n",
    "        subprocess.check_call([\"pip\", \"install\", \"geopandas\"])\n",
    "        print(\"GeoPandas installed successfully!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error installing GeoPandas: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Merged_Data\\paris_merged_calendar.csv loaded successfully!\n",
      "Data from C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\listings.csv loaded successfully!\n",
      "Data from C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\neighbourhoods.csv loaded successfully!\n",
      "Data from C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\neighbourhoods.geojson loaded successfully using GeoPandas!\n",
      "Data from C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\reviews.csv loaded successfully!\n",
      "   listing_id        date  price\n",
      "0        3109  2023-09-05  110.0\n",
      "1        3109  2023-09-06  110.0\n",
      "2        3109  2023-09-07  110.0\n",
      "3        3109  2023-09-08  110.0\n",
      "4        3109  2023-09-09  110.0\n",
      "       id                          listing_url       scrape_id last_scraped  \\\n",
      "0    3109    https://www.airbnb.com/rooms/3109  20240906025355   2024-09-11   \n",
      "1    5396    https://www.airbnb.com/rooms/5396  20240906025355   2024-09-13   \n",
      "2    7397    https://www.airbnb.com/rooms/7397  20240906025355   2024-09-06   \n",
      "3    7964    https://www.airbnb.com/rooms/7964  20240906025355   2024-09-10   \n",
      "4  241715  https://www.airbnb.com/rooms/241715  20240906025355   2024-09-11   \n",
      "\n",
      "            source                                               name  \\\n",
      "0      city scrape                                       zen and calm   \n",
      "1      city scrape       Your perfect Paris studio on ÃŽle Saint-Louis   \n",
      "2      city scrape                   MARAIS - 2ROOMS APT - 2/4 PEOPLE   \n",
      "3  previous scrape                       Sunny apartment with balcony   \n",
      "4      city scrape  Big Cosy Appartement with 100 m2 Terrace in Paris   \n",
      "\n",
      "                                         description  \\\n",
      "0  Lovely Appartment with one bedroom with a Quee...   \n",
      "1  NEW SOFA-BED SINCE JUNE 2023, Please disregard...   \n",
      "2          VERY CONVENIENT, WITH THE BEST LOCATION !   \n",
      "3  We are renting our a spacious, sunny fully fur...   \n",
      "4  Come to stay in our unique Parisian flat to en...   \n",
      "\n",
      "                               neighborhood_overview  \\\n",
      "0  Good restaurants<br />very close the Montparna...   \n",
      "1  You are within walking distance to the Louvre,...   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  The 19th arrondissement of Paris, located in t...   \n",
      "\n",
      "                                         picture_url  host_id  ...  \\\n",
      "0  https://a0.muscache.com/pictures/miso/Hosting-...     3631  ...   \n",
      "1  https://a0.muscache.com/pictures/52413/f9bf76f...     7903  ...   \n",
      "2  https://a0.muscache.com/pictures/67928287/330b...     2626  ...   \n",
      "3  https://a0.muscache.com/pictures/miso/Hosting-...    22155  ...   \n",
      "4  https://a0.muscache.com/pictures/miso/Hosting-...  3342097  ...   \n",
      "\n",
      "  review_scores_communication review_scores_location review_scores_value  \\\n",
      "0                        5.00                   5.00                5.00   \n",
      "1                        4.84                   4.96                4.59   \n",
      "2                        4.89                   4.93                4.74   \n",
      "3                        5.00                   5.00                5.00   \n",
      "4                         NaN                    NaN                 NaN   \n",
      "\n",
      "         license instant_bookable calculated_host_listings_count  \\\n",
      "0  7511409139079                t                              1   \n",
      "1  7510402838018                f                              1   \n",
      "2  7510400829623                f                              1   \n",
      "3  7510903576564                f                              1   \n",
      "4  7511913070313                f                              1   \n",
      "\n",
      "  calculated_host_listings_count_entire_homes  \\\n",
      "0                                           1   \n",
      "1                                           1   \n",
      "2                                           1   \n",
      "3                                           1   \n",
      "4                                           1   \n",
      "\n",
      "  calculated_host_listings_count_private_rooms  \\\n",
      "0                                            0   \n",
      "1                                            0   \n",
      "2                                            0   \n",
      "3                                            0   \n",
      "4                                            0   \n",
      "\n",
      "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
      "0                                           0              0.05  \n",
      "1                                           0              2.23  \n",
      "2                                           0              2.20  \n",
      "3                                           0              0.03  \n",
      "4                                           0               NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "   neighbourhood_group        neighbourhood\n",
      "0                  NaN  Batignolles-Monceau\n",
      "1                  NaN               Bourse\n",
      "2                  NaN      Buttes-Chaumont\n",
      "3                  NaN    Buttes-Montmartre\n",
      "4                  NaN               Ã‰lysÃ©e\n",
      "         neighbourhood neighbourhood_group  \\\n",
      "0  Batignolles-Monceau                None   \n",
      "1       Palais-Bourbon                None   \n",
      "2      Buttes-Chaumont                None   \n",
      "3                OpÃ©ra                None   \n",
      "4             EntrepÃ´t                None   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((2.29517 48.87396, 2.29504 48.8...  \n",
      "1  MULTIPOLYGON (((2.3209 48.86306, 2.32094 48.86...  \n",
      "2  MULTIPOLYGON (((2.38943 48.90122, 2.39014 48.9...  \n",
      "3  MULTIPOLYGON (((2.33978 48.88203, 2.33982 48.8...  \n",
      "4  MULTIPOLYGON (((2.36469 48.88437, 2.36486 48.8...  \n",
      "   listing_id         id        date  reviewer_id reviewer_name  \\\n",
      "0        3109  207127433  2017-10-28     51636494      Patricia   \n",
      "1        3109  208779822  2017-11-03      4142888      Patricia   \n",
      "2        3109  295840159  2018-07-24      7415343       Laurent   \n",
      "3        3109  553502638  2019-10-24     21159216     Anastasia   \n",
      "4        5396       4824  2009-06-30        19995         Sarah   \n",
      "\n",
      "                                            comments  \n",
      "0            Tout s'est bien dÃ©roulÃ©. Merci bien. PG  \n",
      "1  Un petit nid fouiller douillet situÃ© dans  app...  \n",
      "2  Appartement spacieux, propre,clair, et calme Ã ...  \n",
      "3  Appartement totalement rÃ©novÃ©, en parfait Ã©tat...  \n",
      "4  Perfect location!! Nasrine was a delight and m...  \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "merged_calendar = read_dataset(r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Merged_Data\\paris_merged_calendar.csv\")\n",
    "listings = read_dataset(r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\listings.csv\")        \n",
    "neighbourhoods = read_dataset(r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\neighbourhoods.csv\")   \n",
    "neighbourhoods_geojson = read_dataset(r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\neighbourhoods.geojson\")     \n",
    "reviews = read_dataset(r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\reviews.csv\")\n",
    "\n",
    "\n",
    "# If you'd like to inspect the loaded data\n",
    "if merged_calendar is not None:\n",
    "    print(merged_calendar.head())\n",
    "if listings is not None:\n",
    "    print(listings.head())\n",
    "if neighbourhoods is not None:\n",
    "    print(neighbourhoods.head())\n",
    "if neighbourhoods_geojson is not None:\n",
    "    print(neighbourhoods_geojson.head())\n",
    "if reviews is not None:\n",
    "    print(reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'method' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# Replace with your path to the listings.csv file\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m listings\n\u001b[1;32m---> 69\u001b[0m     top_amenities \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_amenities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m, in \u001b[0;36mget_top_amenities\u001b[1;34m(file_path, n)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_top_amenities\u001b[39m(file_path, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Check if amenities column exists\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenities\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\Spatiotemporal_Analytics\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\Spatiotemporal_Analytics\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\Spatiotemporal_Analytics\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\Spatiotemporal_Analytics\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\Spatiotemporal_Analytics\\Lib\\site-packages\\pandas\\io\\common.py:719\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    716\u001b[0m errors \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;66;03m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;00m\n\u001b[1;32m--> 719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_binary_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    720\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# validate encoding and errors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\Spatiotemporal_Analytics\\Lib\\site-packages\\pandas\\io\\common.py:1181\u001b[0m, in \u001b[0;36m_is_binary_mode\u001b[1;34m(handle, mode)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(handle), text_classes):\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, _get_binary_io_classes()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'method' is not iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "def get_top_amenities(file_path, n=20):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if amenities column exists\n",
    "    if 'amenities' not in df.columns:\n",
    "        print(f\"No amenities column found in {file_path}\")\n",
    "        print(f\"Available columns: {', '.join(df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    # Function to parse amenities string to list\n",
    "    def parse_amenities(amenities_str):\n",
    "        try:\n",
    "            # Handle different formats of amenities strings\n",
    "            if pd.isna(amenities_str) or amenities_str == '':\n",
    "                return []\n",
    "            \n",
    "            # Clean the string if needed (remove escape characters, etc.)\n",
    "            cleaned_str = amenities_str\n",
    "            \n",
    "            # If the string is already wrapped in quotes, remove them\n",
    "            if cleaned_str.startswith('\"') and cleaned_str.endswith('\"'):\n",
    "                cleaned_str = cleaned_str[1:-1]\n",
    "            \n",
    "            # Try to parse as JSON\n",
    "            try:\n",
    "                return json.loads(cleaned_str)\n",
    "            except:\n",
    "                # If direct parsing fails, try to fix the format\n",
    "                # Replace single quotes with double quotes if necessary\n",
    "                cleaned_str = re.sub(r\"'\", '\"', cleaned_str)\n",
    "                return json.loads(cleaned_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing amenities: {e}\")\n",
    "            print(f\"Problematic string: {amenities_str[:100]}...\")\n",
    "            return []\n",
    "    \n",
    "    # Apply the function to parse all amenities\n",
    "    print(\"Parsing amenities...\")\n",
    "    amenities_lists = df['amenities'].apply(parse_amenities)\n",
    "    \n",
    "    # Flatten the list of lists into a single list of all amenities\n",
    "    all_amenities = []\n",
    "    for amenities in amenities_lists:\n",
    "        all_amenities.extend(amenities)\n",
    "    \n",
    "    # Count the frequency of each amenity\n",
    "    amenity_counts = Counter(all_amenities)\n",
    "    \n",
    "    # Get the top N most common amenities\n",
    "    top_amenities = amenity_counts.most_common(n)\n",
    "    \n",
    "    print(f\"\\nTop {n} most frequent amenities:\")\n",
    "    for i, (amenity, count) in enumerate(top_amenities, 1):\n",
    "        print(f\"{i}. {amenity}: {count} occurrences\")\n",
    "    \n",
    "    return top_amenities\n",
    "\n",
    "# Usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your path to the listings.csv file\n",
    "    file_path = listings\n",
    "    top_amenities = get_top_amenities(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spatiotemporal_Analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
