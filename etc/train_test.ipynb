{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poorest_neighborhoods_subset...\n",
      "  - Dropping column: available\n",
      "  - Dropping column: neighbourhood_cleansed\n",
      "  - Standardizing column: price\n",
      "  - Standardizing column: accommodates\n",
      "  - Standardizing column: bedrooms\n",
      "  - Standardizing column: bathrooms\n",
      "  - Standardizing column: price_lag_1d\n",
      "  - Standardizing column: price_lag_7d\n",
      "  - Standardizing column: price_lag_30d\n",
      "  - Standardizing column: rolling_mean_7d\n",
      "  - Standardizing column: rolling_max_7d\n",
      "  - Standardizing column: rolling_min_7d\n",
      "  - Standardizing column: rolling_mean_14d\n",
      "  - Standardizing column: rolling_max_14d\n",
      "  - Standardizing column: rolling_min_14d\n",
      "  - Standardizing column: rolling_mean_30d\n",
      "  - Standardizing column: rolling_max_30d\n",
      "  - Standardizing column: rolling_min_30d\n",
      "  - Saved training set with 1221323 rows\n",
      "  - Saved test_feb with 47761 rows\n",
      "  - Saved test_april with 47761 rows\n",
      "  - Saved test_june with 57292 rows\n",
      "Processing richest_neighborhoods_subset...\n",
      "  - Dropping column: available\n",
      "  - Dropping column: neighbourhood_cleansed\n",
      "  - Standardizing column: price\n",
      "  - Standardizing column: accommodates\n",
      "  - Standardizing column: bedrooms\n",
      "  - Standardizing column: bathrooms\n",
      "  - Standardizing column: price_lag_1d\n",
      "  - Standardizing column: price_lag_7d\n",
      "  - Standardizing column: price_lag_30d\n",
      "  - Standardizing column: rolling_mean_7d\n",
      "  - Standardizing column: rolling_max_7d\n",
      "  - Standardizing column: rolling_min_7d\n",
      "  - Standardizing column: rolling_mean_14d\n",
      "  - Standardizing column: rolling_max_14d\n",
      "  - Standardizing column: rolling_min_14d\n",
      "  - Standardizing column: rolling_mean_30d\n",
      "  - Standardizing column: rolling_max_30d\n",
      "  - Standardizing column: rolling_min_30d\n",
      "  - Saved training set with 685107 rows\n",
      "  - Saved test_feb with 26334 rows\n",
      "  - Saved test_april with 26334 rows\n",
      "  - Saved test_june with 31037 rows\n",
      "Processing temporal_features_combined...\n",
      "  - Dropping column: available\n",
      "  - Dropping column: neighbourhood_cleansed\n",
      "  - Standardizing column: price\n",
      "  - Standardizing column: accommodates\n",
      "  - Standardizing column: bedrooms\n",
      "  - Standardizing column: bathrooms\n",
      "  - Standardizing column: price_lag_1d\n",
      "  - Standardizing column: price_lag_7d\n",
      "  - Standardizing column: price_lag_30d\n",
      "  - Standardizing column: rolling_mean_7d\n",
      "  - Standardizing column: rolling_max_7d\n",
      "  - Standardizing column: rolling_min_7d\n",
      "  - Standardizing column: rolling_mean_14d\n",
      "  - Standardizing column: rolling_max_14d\n",
      "  - Standardizing column: rolling_min_14d\n",
      "  - Standardizing column: rolling_mean_30d\n",
      "  - Standardizing column: rolling_max_30d\n",
      "  - Standardizing column: rolling_min_30d\n",
      "  - Saved training set with 8657945 rows\n",
      "  - Saved test_feb with 337442 rows\n",
      "  - Saved test_april with 337442 rows\n",
      "  - Saved test_june with 405428 rows\n",
      "Processing top_cheapest_listings_subset...\n",
      "  - Dropping column: available\n",
      "  - Dropping column: neighbourhood_cleansed\n",
      "  - Standardizing column: price\n",
      "  - Standardizing column: accommodates\n",
      "  - Standardizing column: bedrooms\n",
      "  - Standardizing column: bathrooms\n",
      "  - Standardizing column: price_lag_1d\n",
      "  - Standardizing column: price_lag_7d\n",
      "  - Standardizing column: price_lag_30d\n",
      "  - Standardizing column: rolling_mean_7d\n",
      "  - Standardizing column: rolling_max_7d\n",
      "  - Standardizing column: rolling_min_7d\n",
      "  - Standardizing column: rolling_mean_14d\n",
      "  - Standardizing column: rolling_max_14d\n",
      "  - Standardizing column: rolling_min_14d\n",
      "  - Standardizing column: rolling_mean_30d\n",
      "  - Standardizing column: rolling_max_30d\n",
      "  - Standardizing column: rolling_min_30d\n",
      "  - Saved training set with 1349196 rows\n",
      "  - Saved test_feb with 46067 rows\n",
      "  - Saved test_april with 46067 rows\n",
      "  - Saved test_june with 48941 rows\n",
      "Processing top_expensive_listings_subset...\n",
      "  - Dropping column: available\n",
      "  - Dropping column: neighbourhood_cleansed\n",
      "  - Standardizing column: price\n",
      "  - Standardizing column: accommodates\n",
      "  - Standardizing column: bedrooms\n",
      "  - Standardizing column: bathrooms\n",
      "  - Standardizing column: price_lag_1d\n",
      "  - Standardizing column: price_lag_7d\n",
      "  - Standardizing column: price_lag_30d\n",
      "  - Standardizing column: rolling_mean_7d\n",
      "  - Standardizing column: rolling_max_7d\n",
      "  - Standardizing column: rolling_min_7d\n",
      "  - Standardizing column: rolling_mean_14d\n",
      "  - Standardizing column: rolling_max_14d\n",
      "  - Standardizing column: rolling_min_14d\n",
      "  - Standardizing column: rolling_mean_30d\n",
      "  - Standardizing column: rolling_max_30d\n",
      "  - Standardizing column: rolling_min_30d\n",
      "  - Saved training set with 487852 rows\n",
      "  - Saved test_feb with 23317 rows\n",
      "  - Saved test_april with 23317 rows\n",
      "  - Saved test_june with 36798 rows\n",
      "Processing top_price_changers_subset...\n",
      "  - Dropping column: available\n",
      "  - Dropping column: neighbourhood_cleansed\n",
      "  - Standardizing column: price\n",
      "  - Standardizing column: accommodates\n",
      "  - Standardizing column: bedrooms\n",
      "  - Standardizing column: bathrooms\n",
      "  - Standardizing column: price_lag_1d\n",
      "  - Standardizing column: price_lag_7d\n",
      "  - Standardizing column: price_lag_30d\n",
      "  - Standardizing column: rolling_mean_7d\n",
      "  - Standardizing column: rolling_max_7d\n",
      "  - Standardizing column: rolling_min_7d\n",
      "  - Standardizing column: rolling_mean_14d\n",
      "  - Standardizing column: rolling_max_14d\n",
      "  - Standardizing column: rolling_min_14d\n",
      "  - Standardizing column: rolling_mean_30d\n",
      "  - Standardizing column: rolling_max_30d\n",
      "  - Standardizing column: rolling_min_30d\n",
      "  - Saved training set with 1640389 rows\n",
      "  - Saved test_feb with 55048 rows\n",
      "  - Saved test_april with 55048 rows\n",
      "  - Saved test_june with 55021 rows\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Define date ranges\n",
    "train_dates = {\n",
    "    \"start\": datetime(2023, 7, 8),\n",
    "    \"end\": datetime(2024, 2, 8)\n",
    "}\n",
    "\n",
    "test_sets = [\n",
    "    {\"name\": \"test_feb\", \"start\": datetime(2024, 2, 9), \"end\": datetime(2024, 2, 15)},\n",
    "    {\"name\": \"test_april\", \"start\": datetime(2024, 4, 1), \"end\": datetime(2024, 4, 7)},\n",
    "    {\"name\": \"test_june\", \"start\": datetime(2024, 6, 3), \"end\": datetime(2024, 6, 9)}\n",
    "]\n",
    "\n",
    "# Base directory\n",
    "base_dir = r\"C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\Subset\"\n",
    "\n",
    "# List of subset files\n",
    "subsets = [\n",
    "    \"poorest_neighborhoods_subset\",\n",
    "    \"richest_neighborhoods_subset\",\n",
    "    \"temporal_features_combined\",\n",
    "    \"top_cheapest_listings_subset\",\n",
    "    \"top_expensive_listings_subset\",\n",
    "    \"top_price_changers_subset\"\n",
    "]\n",
    "\n",
    "# Columns to standardize\n",
    "cols_to_standardize = [\n",
    "    \"price\", \"accommodates\", \"bedrooms\", \"bathrooms\", \n",
    "    \"price_lag_1d\", \"price_lag_7d\", \"price_lag_30d\", \n",
    "    \"rolling_mean_7d\", \"rolling_max_7d\", \"rolling_min_7d\", \n",
    "    \"rolling_mean_14d\", \"rolling_max_14d\", \"rolling_min_14d\", \n",
    "    \"rolling_mean_30d\", \"rolling_max_30d\", \"rolling_min_30d\"\n",
    "]\n",
    "\n",
    "# Columns to drop\n",
    "cols_to_drop = [\"available\", \"neighbourhood_cleansed\"]\n",
    "\n",
    "# Create folders and split data\n",
    "for subset in subsets:\n",
    "    print(f\"Processing {subset}...\")\n",
    "    \n",
    "    # Create subset directory\n",
    "    subset_dir = os.path.join(base_dir, subset)\n",
    "    os.makedirs(subset_dir, exist_ok=True)\n",
    "    \n",
    "    # Read the dataset\n",
    "    file_path = os.path.join(base_dir, f\"{subset}.csv\")\n",
    "    df = pl.read_csv(file_path)\n",
    "    \n",
    "    # Convert date column to datetime\n",
    "    df = df.with_columns(pl.col(\"date\").str.to_datetime())\n",
    "    \n",
    "    # Drop specified columns if they exist\n",
    "    for col in cols_to_drop:\n",
    "        if col in df.columns:\n",
    "            print(f\"  - Dropping column: {col}\")\n",
    "            df = df.drop(col)\n",
    "    \n",
    "    # Extract training set\n",
    "    train_df = df.filter(\n",
    "        (pl.col(\"date\") >= pl.lit(train_dates[\"start\"])) & \n",
    "        (pl.col(\"date\") <= pl.lit(train_dates[\"end\"]))\n",
    "    )\n",
    "    \n",
    "    # Standardize columns - compute statistics from training set only\n",
    "    for col in cols_to_standardize:\n",
    "        if col in train_df.columns:\n",
    "            print(f\"  - Standardizing column: {col}\")\n",
    "            # Calculate mean and std from training data\n",
    "            mean_val = train_df.select(pl.col(col).mean()).item()\n",
    "            std_val = train_df.select(pl.col(col).std()).item()\n",
    "            \n",
    "            # Apply standardization to both train and test\n",
    "            if std_val > 0:  # Avoid division by zero\n",
    "                df = df.with_columns(\n",
    "                    ((pl.col(col) - mean_val) / std_val).alias(col)\n",
    "                )\n",
    "    \n",
    "    # Re-extract training set after standardization\n",
    "    train_df = df.filter(\n",
    "        (pl.col(\"date\") >= pl.lit(train_dates[\"start\"])) & \n",
    "        (pl.col(\"date\") <= pl.lit(train_dates[\"end\"]))\n",
    "    )\n",
    "    \n",
    "    # Save training set\n",
    "    train_path = os.path.join(subset_dir, \"train.csv\")\n",
    "    train_df.write_csv(train_path)\n",
    "    print(f\"  - Saved training set with {train_df.height} rows\")\n",
    "    \n",
    "    # Process each test set\n",
    "    for test_set in test_sets:\n",
    "        test_df = df.filter(\n",
    "            (pl.col(\"date\") >= pl.lit(test_set[\"start\"])) & \n",
    "            (pl.col(\"date\") <= pl.lit(test_set[\"end\"]))\n",
    "        )\n",
    "        \n",
    "        # Save test set\n",
    "        test_path = os.path.join(subset_dir, f\"{test_set['name']}.csv\")\n",
    "        test_df.write_csv(test_path)\n",
    "        print(f\"  - Saved {test_set['name']} with {test_df.height} rows\")\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
