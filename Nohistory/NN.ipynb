{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: train_up.csv\n",
      "Loading data...\n",
      "Loading train/test listing IDs...\n",
      "Loaded 6291 train IDs and 1573 test IDs\n",
      "Date range in filtered data: 2023-08-07 00:00:00 to 2024-02-08 00:00:00\n",
      "Number of days with data: 186\n",
      "Warning: No data found between 2023-07-08 and 2023-08-07\n",
      "Using available data starting from 2023-08-07\n",
      "Created 5 test periods:\n",
      "  Period 1: 2024-01-05 to 2024-01-11\n",
      "  Period 2: 2024-01-12 to 2024-01-18\n",
      "  Period 3: 2024-01-19 to 2024-01-25\n",
      "  Period 4: 2024-01-26 to 2024-02-01\n",
      "  Period 5: 2024-02-02 to 2024-02-08\n",
      "Using device: cuda\n",
      "\n",
      "Split 1/5\n",
      "Training period: 2023-08-07 to 2024-01-04\n",
      "Testing period: 2024-01-05 to 2024-01-11\n",
      "Train data: 903142 rows, 6291 unique listings\n",
      "Test data: 11011 rows, 1573 unique listings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "c:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 903142 samples, testing on 11011 samples\n",
      "Epoch [5/20], Loss: 0.0025\n",
      "Epoch [10/20], Loss: 0.0025\n",
      "Epoch [15/20], Loss: 0.0024\n",
      "Epoch [20/20], Loss: 0.0024\n",
      "Split 1 Results - RMSE: 0.6991, MAE: 0.4449, R²: 0.4067, MAPE: 303.61%\n",
      "\n",
      "Split 2/5\n",
      "Training period: 2023-08-07 to 2024-01-11\n",
      "Testing period: 2024-01-12 to 2024-01-18\n",
      "Train data: 947179 rows, 6291 unique listings\n",
      "Test data: 11011 rows, 1573 unique listings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "c:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 947179 samples, testing on 11011 samples\n",
      "Epoch [5/20], Loss: 0.0026\n",
      "Epoch [10/20], Loss: 0.0025\n",
      "Epoch [15/20], Loss: 0.0025\n",
      "Epoch [20/20], Loss: 0.0025\n",
      "Split 2 Results - RMSE: 0.6831, MAE: 0.4369, R²: 0.4060, MAPE: 277.34%\n",
      "\n",
      "Split 3/5\n",
      "Training period: 2023-08-07 to 2024-01-18\n",
      "Testing period: 2024-01-19 to 2024-01-25\n",
      "Train data: 991216 rows, 6291 unique listings\n",
      "Test data: 11011 rows, 1573 unique listings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 805\u001b[0m\n\u001b[0;32m    802\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmvk\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDATA_school\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mthesis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSTRAP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTopic2_ListingSplit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Run the model\u001b[39;00m\n\u001b[1;32m--> 805\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_rolling_window_strap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ids_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ids_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_ids_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ids_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 5 weeks\u001b[39;49;00m\n\u001b[0;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to a number like 1000 for testing, None to use all data\u001b[39;49;00m\n\u001b[0;32m    813\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 389\u001b[0m, in \u001b[0;36mrun_rolling_window_strap\u001b[1;34m(train_path, train_ids_path, test_ids_path, output_dir, window_size, n_splits, sample_size)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Create spatial features using only training data as reference\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# Pass training data to prevent leakage\u001b[39;00m\n\u001b[0;32m    388\u001b[0m full_train_data \u001b[38;5;241m=\u001b[39m train_data[train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlisting_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(train_listing_ids)]\n\u001b[1;32m--> 389\u001b[0m train_spatial \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_spatial_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_train_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m test_spatial \u001b[38;5;241m=\u001b[39m create_spatial_features(split_test_data, train_data_only\u001b[38;5;241m=\u001b[39mfull_train_data)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Prepare feature matrices\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 224\u001b[0m, in \u001b[0;36mcreate_spatial_features\u001b[1;34m(df, k_neighbors, chunk_size, n_jobs, train_data_only)\u001b[0m\n\u001b[0;32m    221\u001b[0m n_chunks \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m/\u001b[39m chunk_size)\n\u001b[0;32m    222\u001b[0m chunks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(df, n_chunks)\n\u001b[1;32m--> 224\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43menhanced_process_chunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactual_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use adjusted k value\u001b[39;49;00m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_prices\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Combine results\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m spatial_data\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, max_error, median_absolute_error\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neighbors import BallTree\n",
    "from math import radians\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class STRAP(nn.Module):\n",
    "    \"\"\"ST-RAP model with sequence processing capabilities\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_gru_layers=2):\n",
    "        super(STRAP, self).__init__()\n",
    "        \n",
    "        # Property feature embedding\n",
    "        self.property_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Temporal GRU layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_gru_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Spatial graph layers\n",
    "        self.graph_conv = SAGEConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Normalization\n",
    "        self.temporal_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.spatial_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Final prediction layers\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index=None, time_features=None):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Process property features\n",
    "        property_emb = self.property_embedding(x)\n",
    "        \n",
    "        # Create a sequence of property features (repeated)\n",
    "        # For simplicity, we use a simple approach where current features are repeated\n",
    "        seq_length = 5  # Using a fixed sequence length\n",
    "        sequence = property_emb.unsqueeze(1).repeat(1, seq_length, 1)\n",
    "        \n",
    "        # Process with GRU\n",
    "        gru_output, _ = self.gru(sequence)\n",
    "        \n",
    "        # Apply attention to focus on most relevant timesteps\n",
    "        attention_weights = self.attention(gru_output)\n",
    "        context_vector = torch.sum(attention_weights * gru_output, dim=1)\n",
    "        temporal_output = self.temporal_norm(context_vector)\n",
    "        \n",
    "        # Process with graph convolution if edge_index provided\n",
    "        if edge_index is not None and edge_index.numel() > 0:\n",
    "            spatial_output = self.graph_conv(property_emb, edge_index)\n",
    "            spatial_output = self.spatial_norm(spatial_output)\n",
    "        else:\n",
    "            spatial_output = property_emb\n",
    "        \n",
    "        # Combine temporal and spatial outputs\n",
    "        combined = torch.cat([temporal_output, spatial_output], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        output = self.predictor(combined).squeeze(-1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate the distance between two points using the Haversine formula.\"\"\"\n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def create_spatial_features(df, k_neighbors=5, chunk_size=1000, n_jobs=-1, train_data_only=None):\n",
    "    \"\"\"Enhanced spatial features while maintaining existing structure\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The data to create features for\n",
    "    k_neighbors : int\n",
    "        Number of neighbors to use for KNN features\n",
    "    chunk_size : int\n",
    "        Size of chunks for parallel processing\n",
    "    n_jobs : int\n",
    "        Number of parallel jobs\n",
    "    train_data_only : DataFrame, optional\n",
    "        If provided, use only this data for computing the KNN features\n",
    "        This prevents data leakage by ensuring test listings don't influence each other\n",
    "    \"\"\"\n",
    "    # Adjust k_neighbors if the dataset is small\n",
    "    reference_data = train_data_only if train_data_only is not None else df\n",
    "    actual_k = min(k_neighbors, len(reference_data) - 1)  # Make sure k is at most n-1\n",
    "    if actual_k < k_neighbors:\n",
    "        print(f\"Reducing k_neighbors from {k_neighbors} to {actual_k} due to small sample size\")\n",
    "    \n",
    "    city_center_lat, city_center_lon = 48.8566, 2.3522\n",
    "    \n",
    "    # Initialize spatial features\n",
    "    spatial_data = {\n",
    "        'distance_to_center': [],\n",
    "        'north_south': [],\n",
    "        'knn_price_mean': [],\n",
    "        'knn_price_std': [],\n",
    "        'knn_price_median': [],\n",
    "        'knn_price_range': [],\n",
    "        'price_diff_from_neighbors': [],\n",
    "        'distance_weighted_price': []\n",
    "    }\n",
    "    \n",
    "    # Calculate basic distance features\n",
    "    spatial_data['distance_to_center'] = df.apply(\n",
    "        lambda row: calculate_distance(\n",
    "            row['latitude'], \n",
    "            row['longitude'], \n",
    "            city_center_lat, \n",
    "            city_center_lon\n",
    "        ),\n",
    "        axis=1\n",
    "    ).values\n",
    "    \n",
    "    spatial_data['north_south'] = (df['latitude'] - city_center_lat).values\n",
    "    \n",
    "    # Enhanced BallTree processing\n",
    "    # Use only training data for the reference tree to prevent data leakage\n",
    "    all_coords = np.radians(reference_data[['latitude', 'longitude']].values)\n",
    "    tree = BallTree(all_coords, metric='haversine')\n",
    "    all_prices = reference_data['price'].values\n",
    "    \n",
    "    def enhanced_process_chunk(chunk_data, tree, k_neighbors, all_prices):\n",
    "        \"\"\"Enhanced chunk processing with additional metrics\"\"\"\n",
    "        coords = np.radians(chunk_data[['latitude', 'longitude']].values)\n",
    "        # Use adaptive k value\n",
    "        k_query = min(k_neighbors + 1, len(all_coords))\n",
    "        distances, indices = tree.query(coords, k=k_query)\n",
    "        \n",
    "        # Handle special cases with small datasets\n",
    "        if k_query == 1:\n",
    "            # Just return zeros or appropriate values for a single point\n",
    "            n_samples = len(chunk_data)\n",
    "            return {\n",
    "                'knn_price_mean': np.zeros(n_samples),\n",
    "                'knn_price_std': np.zeros(n_samples),\n",
    "                'knn_price_median': np.zeros(n_samples),\n",
    "                'knn_price_range': np.zeros(n_samples),\n",
    "                'price_diff_from_neighbors': np.zeros(n_samples),\n",
    "                'distance_weighted_price': np.zeros(n_samples)\n",
    "            }\n",
    "        \n",
    "        # Process neighbor data if we have multiple points\n",
    "        if k_query == 2:\n",
    "            neighbor_prices = np.take(all_prices, indices[:, 1:]).reshape(-1, 1)\n",
    "            weights = np.ones((len(distances), 1))  # Only one neighbor, so weight is 1\n",
    "        else:\n",
    "            # Convert distances to weights (inverse distance weighting)\n",
    "            weights = 1 / (distances[:, 1:] + 1e-6)  # Add small epsilon to avoid division by zero\n",
    "            weights = weights / weights.sum(axis=1, keepdims=True)\n",
    "            neighbor_prices = np.take(all_prices, indices[:, 1:])\n",
    "        \n",
    "        # Calculate neighbor statistics\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)  # Ignore NaN warnings\n",
    "            mean_prices = np.nanmean(neighbor_prices, axis=1)\n",
    "            std_prices = np.nanstd(neighbor_prices, axis=1)\n",
    "            \n",
    "            # Handle single-neighbor case for median and range\n",
    "            if neighbor_prices.shape[1] == 1:\n",
    "                median_prices = neighbor_prices.flatten()\n",
    "                range_prices = np.zeros(len(neighbor_prices))\n",
    "            else:\n",
    "                median_prices = np.nanmedian(neighbor_prices, axis=1)\n",
    "                range_prices = np.ptp(neighbor_prices, axis=1)\n",
    "            \n",
    "            # Weighted prices\n",
    "            if neighbor_prices.shape[1] == 1:\n",
    "                weighted_prices = neighbor_prices.flatten()\n",
    "            else:\n",
    "                weighted_prices = np.sum(weights * neighbor_prices, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'knn_price_mean': mean_prices,\n",
    "            'knn_price_std': std_prices,\n",
    "            'knn_price_median': median_prices,\n",
    "            'knn_price_range': range_prices,\n",
    "            'price_diff_from_neighbors': chunk_data['price'].values - mean_prices,\n",
    "            'distance_weighted_price': weighted_prices\n",
    "        }\n",
    "    \n",
    "    # Split and process chunks\n",
    "    n_chunks = math.ceil(len(df) / chunk_size)\n",
    "    chunks = np.array_split(df, n_chunks)\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(enhanced_process_chunk)(\n",
    "            chunk, \n",
    "            tree, \n",
    "            actual_k,  # Use adjusted k value\n",
    "            all_prices\n",
    "        ) for chunk in chunks\n",
    "    )\n",
    "    \n",
    "    # Combine results\n",
    "    for key in spatial_data.keys():\n",
    "        if key not in ['distance_to_center', 'north_south']:\n",
    "            spatial_data[key] = np.concatenate([r[key] for r in results])\n",
    "    \n",
    "    spatial_features = pd.DataFrame(spatial_data, index=df.index)\n",
    "    \n",
    "    # Standardize features\n",
    "    features_to_standardize = list(spatial_data.keys())\n",
    "    \n",
    "    for col in features_to_standardize:\n",
    "        mean_val = spatial_features[col].mean()\n",
    "        std_val = spatial_features[col].std()\n",
    "        # Avoid division by zero\n",
    "        if std_val > 0:\n",
    "            spatial_features[col] = (spatial_features[col] - mean_val) / std_val\n",
    "        else:\n",
    "            spatial_features[col] = 0  # Set to zero if std is zero\n",
    "    \n",
    "    return spatial_features\n",
    "\n",
    "def run_rolling_window_strap(train_path, train_ids_path, test_ids_path, output_dir=None, window_size=35, n_splits=5, sample_size=None):\n",
    "    \"\"\"\n",
    "    Run STRAP neural network with rolling window cross-validation for predicting prices without price history.\n",
    "    Uses separate listing IDs for training and testing to prevent data leakage.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_path : str\n",
    "        Path to the training CSV file\n",
    "    train_ids_path : str\n",
    "        Path to text file with training listing IDs\n",
    "    test_ids_path : str\n",
    "        Path to text file with test listing IDs\n",
    "    output_dir : str, optional\n",
    "        Directory to save results\n",
    "    window_size : int, optional\n",
    "        Size of the rolling window in days\n",
    "    n_splits : int, optional\n",
    "        Number of splits for time series cross-validation\n",
    "    sample_size : int, optional\n",
    "        Limit dataset to this number of random listings (for testing)\n",
    "    \"\"\"\n",
    "    print(f\"Processing dataset: {os.path.basename(train_path)}\")\n",
    "    \n",
    "    # Load training data\n",
    "    print(\"Loading data...\")\n",
    "    train_data = pd.read_csv(train_path)\n",
    "\n",
    "    # Load listing IDs for train/test split\n",
    "    print(\"Loading train/test listing IDs...\")\n",
    "    with open(train_ids_path, 'r') as f:\n",
    "        train_listing_ids = [int(line.strip()) for line in f.readlines()]\n",
    "        \n",
    "    with open(test_ids_path, 'r') as f:\n",
    "        test_listing_ids = [int(line.strip()) for line in f.readlines()]\n",
    "    \n",
    "    print(f\"Loaded {len(train_listing_ids)} train IDs and {len(test_listing_ids)} test IDs\")\n",
    "\n",
    "    # Drop legacy price columns if they exist\n",
    "    for col in ['price_lag_1d', 'simulated_price']:\n",
    "        if col in train_data.columns:\n",
    "            print(f\"Dropping {col} column from the dataset\")\n",
    "            train_data = train_data.drop(col, axis=1)\n",
    "    \n",
    "    # For testing - take only a small sample of listings if specified\n",
    "    if sample_size:\n",
    "        print(f\"Limiting to {sample_size} random listings for testing\")\n",
    "        selected_train = np.random.choice(train_listing_ids, int(sample_size * 0.7), replace=False)\n",
    "        selected_test = np.random.choice(test_listing_ids, int(sample_size * 0.3), replace=False)\n",
    "        train_listing_ids = selected_train.tolist()\n",
    "        test_listing_ids = selected_test.tolist()\n",
    "    \n",
    "    # Convert date column to datetime\n",
    "    train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "    \n",
    "    # Filter data to include only dates from 7/8/23 till 2/8/24\n",
    "    start_date = pd.to_datetime('2023-07-08')\n",
    "    end_date = pd.to_datetime('2024-02-08')\n",
    "    train_data = train_data[(train_data['date'] >= start_date) & (train_data['date'] <= end_date)]\n",
    "    \n",
    "    # Check if we have data for the entire expected range\n",
    "    print(f\"Date range in filtered data: {train_data['date'].min()} to {train_data['date'].max()}\")\n",
    "    print(f\"Number of days with data: {len(train_data['date'].dt.date.unique())}\")\n",
    "\n",
    "    # Get unique dates and ensure they are properly sorted\n",
    "    unique_dates = sorted(train_data['date'].dt.date.unique())\n",
    "    first_date = unique_dates[0]\n",
    "    last_date = unique_dates[-1]\n",
    "\n",
    "    # Check if there's a gap between the expected start date and actual first date\n",
    "    if first_date > start_date.date():\n",
    "        print(f\"Warning: No data found between {start_date.date()} and {first_date}\")\n",
    "        print(f\"Using available data starting from {first_date}\")\n",
    "    \n",
    "    # Sort by date\n",
    "    train_data = train_data.sort_values('date')\n",
    "    \n",
    "    # Create explicit test periods - last 5 weeks (35 days) split into 5 equal parts (7 days each)\n",
    "    last_35_days = unique_dates[-35:]\n",
    "    \n",
    "    # Define explicit test periods - each 7 days\n",
    "    test_periods = []\n",
    "    for i in range(n_splits):\n",
    "        start_idx = i * 7\n",
    "        end_idx = start_idx + 7\n",
    "        # Make sure we don't go beyond the available data\n",
    "        if end_idx <= len(last_35_days):\n",
    "            test_periods.append((last_35_days[start_idx], last_35_days[end_idx-1]))\n",
    "    \n",
    "    # Adjust n_splits if we couldn't create enough test periods\n",
    "    n_splits = len(test_periods)\n",
    "    \n",
    "    print(f\"Created {n_splits} test periods:\")\n",
    "    for i, (test_start, test_end) in enumerate(test_periods):\n",
    "        print(f\"  Period {i+1}: {test_start} to {test_end}\")\n",
    "    \n",
    "    # Initialize STRAP model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Storage for results\n",
    "    cv_results = []\n",
    "    feature_importance_over_time = []  # We'll simulate this for the NN model\n",
    "    \n",
    "    # Run time series cross-validation using our explicit test periods\n",
    "    for i, (test_start, test_end) in enumerate(test_periods):\n",
    "        print(f\"\\nSplit {i+1}/{n_splits}\")\n",
    "        \n",
    "        # Define training period: everything before test_start\n",
    "        train_end = pd.to_datetime(test_start) - pd.Timedelta(days=1)\n",
    "        train_end_date = train_end.date()\n",
    "        \n",
    "        print(f\"Training period: {unique_dates[0]} to {train_end_date}\")\n",
    "        print(f\"Testing period: {test_start} to {test_end}\")\n",
    "        \n",
    "        # Split by date first\n",
    "        train_date_mask = train_data['date'].dt.date <= train_end_date\n",
    "        test_date_mask = (train_data['date'].dt.date >= test_start) & (train_data['date'].dt.date <= test_end)\n",
    "        \n",
    "        date_filtered_train = train_data[train_date_mask]\n",
    "        date_filtered_test = train_data[test_date_mask]\n",
    "        \n",
    "        # Now further split by listing IDs\n",
    "        train_id_mask = date_filtered_train['listing_id'].isin(train_listing_ids)\n",
    "        test_id_mask = date_filtered_test['listing_id'].isin(test_listing_ids)\n",
    "        \n",
    "        split_train_data = date_filtered_train[train_id_mask]\n",
    "        split_test_data = date_filtered_test[test_id_mask]\n",
    "        \n",
    "        print(f\"Train data: {len(split_train_data)} rows, {len(split_train_data['listing_id'].unique())} unique listings\")\n",
    "        print(f\"Test data: {len(split_test_data)} rows, {len(split_test_data['listing_id'].unique())} unique listings\")\n",
    "        \n",
    "        # Create spatial features using only training data as reference\n",
    "        # Pass training data to prevent leakage\n",
    "        full_train_data = train_data[train_data['listing_id'].isin(train_listing_ids)]\n",
    "        train_spatial = create_spatial_features(split_train_data, train_data_only=full_train_data)\n",
    "        test_spatial = create_spatial_features(split_test_data, train_data_only=full_train_data)\n",
    "        \n",
    "        # Prepare feature matrices\n",
    "        X_train = pd.concat([\n",
    "            split_train_data.drop(['listing_id', 'date', 'price'], axis=1), \n",
    "            train_spatial\n",
    "        ], axis=1)\n",
    "        \n",
    "        X_test = pd.concat([\n",
    "            split_test_data.drop(['listing_id', 'date', 'price'], axis=1), \n",
    "            test_spatial\n",
    "        ], axis=1)\n",
    "        \n",
    "        y_train = split_train_data['price']\n",
    "        y_test = split_test_data['price']\n",
    "        \n",
    "        # Ensure X_train and X_test have the same columns\n",
    "        missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "        for col in missing_cols:\n",
    "            X_test[col] = 0\n",
    "            \n",
    "        # Ensure the columns are in the same order\n",
    "        X_test = X_test[X_train.columns]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "        y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "        X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "        \n",
    "        # Initialize model for this split\n",
    "        model = STRAP(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_dim=128\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define optimizer and loss function\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Create DataLoader for training\n",
    "        train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        \n",
    "        # Train the model\n",
    "        print(f\"Training on {len(X_train)} samples, testing on {len(X_test)} samples\")\n",
    "        model.train()\n",
    "        num_epochs = 20\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0\n",
    "            batch_count = 0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                batch_count += 1\n",
    "            \n",
    "            # Print progress every 5 epochs\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/batch_count:.4f}')\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        model.eval()\n",
    "        X_test_tensor = X_test_tensor.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_test_tensor).cpu().numpy()\n",
    "        \n",
    "        # Generate simulated feature importance for visualization\n",
    "        # (real feature importance isn't directly available for neural networks)\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': np.random.uniform(0, 1, size=X_train.shape[1]),  # Random placeholder values\n",
    "            'split': i\n",
    "        })\n",
    "        feature_importance_over_time.append(feature_importance)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred) if len(set(y_test)) > 1 else np.nan\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100\n",
    "        \n",
    "        print(f\"Split {i+1} Results - RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}, MAPE: {mape:.2f}%\")\n",
    "        \n",
    "        # Store results for this split\n",
    "        split_results = pd.DataFrame({\n",
    "            'split': i,\n",
    "            'date': split_test_data['date'],\n",
    "            'listing_id': split_test_data['listing_id'],\n",
    "            'price': y_test,\n",
    "            'predicted': y_pred,\n",
    "            'error': y_test - y_pred,\n",
    "            'abs_error': np.abs(y_test - y_pred),\n",
    "            'pct_error': np.abs((y_test - y_pred) / (y_test + 1e-8)) * 100\n",
    "        })\n",
    "        \n",
    "        cv_results.append(split_results)\n",
    "    \n",
    "    # Combine all results\n",
    "    all_results = pd.concat(cv_results, ignore_index=True)\n",
    "    all_feature_importance = pd.concat(feature_importance_over_time, ignore_index=True)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    y_true = all_results['price']\n",
    "    y_pred = all_results['predicted']\n",
    "    \n",
    "    overall_metrics = {\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'r2': r2_score(y_true, y_pred),\n",
    "        'mape': np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100,\n",
    "        'explained_variance': explained_variance_score(y_true, y_pred),\n",
    "        'max_error': max_error(y_true, y_pred),\n",
    "        'median_absolute_error': median_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Calculate split-level metrics\n",
    "    split_metrics = []\n",
    "    for split in range(n_splits):\n",
    "        split_data = all_results[all_results['split'] == split]\n",
    "        if not split_data.empty:\n",
    "            y_true_split = split_data['price']\n",
    "            y_pred_split = split_data['predicted']\n",
    "            \n",
    "            split_metrics.append({\n",
    "                'split': split,\n",
    "                'rmse': np.sqrt(mean_squared_error(y_true_split, y_pred_split)),\n",
    "                'mae': mean_absolute_error(y_true_split, y_pred_split),\n",
    "                'r2': r2_score(y_true_split, y_pred_split) if len(set(y_true_split)) > 1 else np.nan,\n",
    "                'mape': np.mean(np.abs((y_true_split - y_pred_split) / (y_true_split + 1e-8))) * 100,\n",
    "                'n_samples': len(y_true_split)\n",
    "            })\n",
    "    \n",
    "    split_metrics_df = pd.DataFrame(split_metrics)\n",
    "    \n",
    "    # Calculate daily metrics\n",
    "    all_results['date_str'] = pd.to_datetime(all_results['date']).dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    daily_metrics = []\n",
    "    for day, group in all_results.groupby('date_str'):\n",
    "        y_true_day = group['price']\n",
    "        y_pred_day = group['predicted']\n",
    "        \n",
    "        daily_metrics.append({\n",
    "            'date': day,\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true_day, y_pred_day)),\n",
    "            'mae': mean_absolute_error(y_true_day, y_pred_day),\n",
    "            'r2': r2_score(y_true_day, y_pred_day) if len(set(y_true_day)) > 1 else np.nan,\n",
    "            'mape': np.mean(np.abs((y_true_day - y_pred_day) / (y_true_day + 1e-8))) * 100,\n",
    "            'n_samples': len(y_true_day)\n",
    "        })\n",
    "    \n",
    "    daily_metrics_df = pd.DataFrame(daily_metrics)\n",
    "    daily_metrics_df['date'] = pd.to_datetime(daily_metrics_df['date'])\n",
    "    daily_metrics_df = daily_metrics_df.sort_values('date')\n",
    "    \n",
    "    # Error analysis\n",
    "    errors = all_results['error'].values\n",
    "    error_autocorr = acf(errors, nlags=7)[1:]  # Exclude lag 0\n",
    "    \n",
    "    # Create a results dictionary\n",
    "    evaluation_results = {\n",
    "        'overall_metrics': overall_metrics,\n",
    "        'split_metrics': split_metrics_df,\n",
    "        'daily_metrics': daily_metrics_df,\n",
    "        'all_results': all_results,\n",
    "        'feature_importance': all_feature_importance,\n",
    "        'error_autocorrelation': error_autocorr,\n",
    "        'train_listings': len(train_listing_ids),\n",
    "        'test_listings': len(test_listing_ids)\n",
    "    }\n",
    "    \n",
    "    # Save results if output directory is provided\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save all results\n",
    "        results_file = os.path.join(output_dir, 'strap_listing_split_results.csv')\n",
    "        all_results.to_csv(results_file, index=False)\n",
    "        print(f\"Results saved to {results_file}\")\n",
    "        \n",
    "        # Save metrics\n",
    "        metrics_file = os.path.join(output_dir, 'strap_listing_split_metrics.csv')\n",
    "        daily_metrics_df.to_csv(metrics_file, index=False)\n",
    "        print(f\"Daily metrics saved to {metrics_file}\")\n",
    "        \n",
    "        # Save feature importance\n",
    "        importance_file = os.path.join(output_dir, 'strap_listing_split_feature_importance.csv')\n",
    "        all_feature_importance.to_csv(importance_file, index=False)\n",
    "        print(f\"Feature importance saved to {importance_file}\")\n",
    "        \n",
    "        # Save summary\n",
    "        with open(os.path.join(output_dir, 'summary.txt'), 'w') as f:\n",
    "            f.write(f\"STRAP Neural Network Rolling Window CV Model Summary with Listing ID Split\\n\")\n",
    "            f.write(f\"==========================================================\\n\\n\")\n",
    "            f.write(f\"Window size: {window_size} days\\n\")\n",
    "            f.write(f\"Number of splits: {n_splits}\\n\")\n",
    "            f.write(f\"Training period: {unique_dates[0]} to {unique_dates[-1]}\\n\")\n",
    "            f.write(f\"Number of training listings: {len(train_listing_ids)}\\n\")\n",
    "            f.write(f\"Number of test listings: {len(test_listing_ids)}\\n\\n\")\n",
    "            f.write(f\"Overall Metrics:\\n\")\n",
    "            for k, v in overall_metrics.items():\n",
    "                f.write(f\"  {k}: {v:.6f}\\n\")\n",
    "    \n",
    "    # Print summary\n",
    "    print_rolling_window_summary(evaluation_results)\n",
    "    \n",
    "    # Create plots\n",
    "    plot_rolling_window_results(evaluation_results)\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "def print_rolling_window_summary(evaluation_results):\n",
    "    \"\"\"Print a summary of rolling window cross-validation results\"\"\"\n",
    "    overall = evaluation_results['overall_metrics']\n",
    "    splits = evaluation_results['split_metrics']\n",
    "    daily = evaluation_results['daily_metrics']\n",
    "    feature_importance = evaluation_results['feature_importance']\n",
    "    error_autocorr = evaluation_results.get('error_autocorrelation', [0] * 7)\n",
    "    \n",
    "    # Print new info about listing splits if available\n",
    "    train_listings = evaluation_results.get('train_listings', 'N/A')\n",
    "    test_listings = evaluation_results.get('test_listings', 'N/A')\n",
    "    \n",
    "    print(\"\\n===== ROLLING WINDOW STRAP MODEL WITH LISTING ID SPLIT =====\")\n",
    "    if train_listings != 'N/A':\n",
    "        print(f\"Using {train_listings} listings for training and {test_listings} listings for testing\")\n",
    "    \n",
    "    print(\"\\n=== Overall Metrics ===\")\n",
    "    print(f\"RMSE: {overall['rmse']:.4f}\")\n",
    "    print(f\"MAE: {overall['mae']:.4f}\")\n",
    "    print(f\"R²: {overall['r2']:.4f}\")\n",
    "    print(f\"MAPE: {overall['mape']:.4f}%\")\n",
    "    print(f\"Explained Variance: {overall['explained_variance']:.4f}\")\n",
    "    print(f\"Median Abs Error: {overall['median_absolute_error']:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Split Performance ===\")\n",
    "    print(splits[['split', 'rmse', 'mae', 'mape', 'r2', 'n_samples']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n=== Split Statistics ===\")\n",
    "    print(\"MAE:\")\n",
    "    print(f\"  Average: {splits['mae'].mean():.4f}\")\n",
    "    print(f\"  Min: {splits['mae'].min():.4f} (Split {splits.loc[splits['mae'].idxmin(), 'split']})\")\n",
    "    print(f\"  Max: {splits['mae'].max():.4f} (Split {splits.loc[splits['mae'].idxmax(), 'split']})\")\n",
    "    \n",
    "    print(\"\\nRMSE:\")\n",
    "    print(f\"  Average: {splits['rmse'].mean():.4f}\")\n",
    "    print(f\"  Min: {splits['rmse'].min():.4f} (Split {splits.loc[splits['rmse'].idxmin(), 'split']})\")\n",
    "    print(f\"  Max: {splits['rmse'].max():.4f} (Split {splits.loc[splits['rmse'].idxmax(), 'split']})\")\n",
    "    \n",
    "    print(\"\\n=== Error Autocorrelation ===\")\n",
    "    for lag, acf_value in enumerate(error_autocorr, 1):\n",
    "        print(f\"  Lag {lag}: {acf_value:.4f}\")\n",
    "    \n",
    "    # For neural networks, we don't have real feature importance\n",
    "    # but we can report other important model characteristics\n",
    "    print(\"\\n=== Model Information ===\")\n",
    "    print(\"Neural network architecture: STRAP (Spatio-Temporal Real estate APpraisal)\")\n",
    "    print(\"Components: GRU for temporal modeling, Graph convolutional layers for spatial modeling\")\n",
    "    print(\"Note: Neural networks don't provide direct feature importance like tree-based models\")\n",
    "\n",
    "def plot_rolling_window_results(evaluation_results):\n",
    "    \"\"\"Plot the results from rolling window cross-validation\"\"\"\n",
    "    # Set style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    \n",
    "    # Extract data\n",
    "    daily_metrics = evaluation_results['daily_metrics']\n",
    "    all_results = evaluation_results['all_results']\n",
    "    splits = evaluation_results['split_metrics']\n",
    "    \n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Add title showing we're using listing ID split\n",
    "    fig.suptitle('STRAP Neural Network Evaluation with Listing ID Split', fontsize=16)\n",
    "    \n",
    "    # Plot 1: Daily MAE\n",
    "    sns.lineplot(\n",
    "        x=pd.to_datetime(daily_metrics['date']),\n",
    "        y=daily_metrics['mae'],\n",
    "        marker='o',\n",
    "        ax=axes[0, 0]\n",
    "    )\n",
    "    axes[0, 0].set_title('Mean Absolute Error by Day')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel('MAE')\n",
    "    axes[0, 0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    axes[0, 0].xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    plt.setp(axes[0, 0].xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 2: Cross-validation splits performance\n",
    "    splits_x = splits['split']\n",
    "    metrics_to_plot = ['rmse', 'mae']\n",
    "    \n",
    "    for metric in metrics_to_plot:\n",
    "        sns.lineplot(\n",
    "            x=splits_x,\n",
    "            y=splits[metric],\n",
    "            marker='o',\n",
    "            label=metric.upper(),\n",
    "            ax=axes[0, 1]\n",
    "        )\n",
    "    \n",
    "    axes[0, 1].set_title('Performance Across CV Splits')\n",
    "    axes[0, 1].set_xlabel('CV Split')\n",
    "    axes[0, 1].set_ylabel('Error Metric')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Plot 3: Actual vs Predicted (colored by split)\n",
    "    scatter = axes[1, 0].scatter(\n",
    "        all_results['price'],\n",
    "        all_results['predicted'],\n",
    "        c=all_results['split'],\n",
    "        alpha=0.6,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    min_val = min(all_results['price'].min(), all_results['predicted'].min())\n",
    "    max_val = max(all_results['price'].max(), all_results['predicted'].max())\n",
    "    axes[1, 0].plot([min_val, max_val], [min_val, max_val], 'k--')\n",
    "    axes[1, 0].set_title('Actual vs Predicted (Colored by CV Split)')\n",
    "    axes[1, 0].set_xlabel('Actual')\n",
    "    axes[1, 0].set_ylabel('Predicted')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=axes[1, 0])\n",
    "    cbar.set_label('CV Split')\n",
    "    \n",
    "    # Plot 4: Error distribution\n",
    "    sns.histplot(all_results['error'], kde=True, ax=axes[1, 1])\n",
    "    axes[1, 1].axvline(0, color='r', linestyle='--')\n",
    "    axes[1, 1].set_title('Error Distribution')\n",
    "    axes[1, 1].set_xlabel('Error (Actual - Predicted)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)  # Make room for the suptitle\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot error autocorrelation\n",
    "    error_acf = np.concatenate([[1], evaluation_results['error_autocorrelation']])\n",
    "    lags = range(len(error_acf))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(lags, error_acf, alpha=0.7)\n",
    "    plt.axhline(y=0, linestyle='--', color='gray')\n",
    "    \n",
    "    # Add confidence intervals (95%)\n",
    "    conf_interval = 1.96 / np.sqrt(len(all_results['error']))\n",
    "    plt.axhline(y=conf_interval, linestyle='--', color='red', alpha=0.5)\n",
    "    plt.axhline(y=-conf_interval, linestyle='--', color='red', alpha=0.5)\n",
    "    \n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.title('Error Autocorrelation')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional plot: Performance by listing ID count\n",
    "    # Group by listing ID and calculate average absolute error for each listing\n",
    "    listing_errors = all_results.groupby('listing_id')['abs_error'].mean().reset_index()\n",
    "    listing_errors = listing_errors.sort_values('abs_error')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(range(len(listing_errors)), listing_errors['abs_error'], alpha=0.6)\n",
    "    plt.axhline(y=listing_errors['abs_error'].mean(), color='r', linestyle='--', \n",
    "                label=f'Mean: {listing_errors[\"abs_error\"].mean():.2f}')\n",
    "    plt.title('Average Absolute Error by Listing')\n",
    "    plt.xlabel('Listing Index (sorted by error)')\n",
    "    plt.ylabel('Mean Absolute Error')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # For neural networks, we might want additional visualizations\n",
    "    # Plot spatial error distribution if we have location data\n",
    "    if 'latitude' in all_results.columns and 'longitude' in all_results.columns:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.scatter(\n",
    "            all_results['longitude'], \n",
    "            all_results['latitude'], \n",
    "            c=all_results['abs_error'],\n",
    "            alpha=0.6,\n",
    "            cmap='YlOrRd'\n",
    "        )\n",
    "        plt.colorbar(label='Absolute Error')\n",
    "        plt.title('Spatial Distribution of Prediction Errors')\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to data files\n",
    "    train_path = r\"C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\Subset\\top_price_changers_subset\\train_up.csv\"\n",
    "    train_ids_path = r\"C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\Subset\\top_price_changers_subset\\train_ids.txt\"\n",
    "    test_ids_path = r\"C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\Subset\\top_price_changers_subset\\test_ids.txt\"\n",
    "    \n",
    "    # Output directory\n",
    "    output_dir = r\"C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\Output\\STRAP\\Topic2_ListingSplit\"\n",
    "    \n",
    "    # Run the model\n",
    "    results = run_rolling_window_strap(\n",
    "        train_path=train_path,\n",
    "        train_ids_path=train_ids_path,\n",
    "        test_ids_path=test_ids_path,\n",
    "        output_dir=output_dir,\n",
    "        window_size=35,  # 5 weeks\n",
    "        n_splits=5,\n",
    "        sample_size=None  # Set to a number like 1000 for testing, None to use all data\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
