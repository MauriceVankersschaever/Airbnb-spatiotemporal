{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        # Get the number of available GPUs\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "        print(f\"Number of GPUs available: {n_gpu}\")\n",
    "        \n",
    "        if n_gpu >= 3:  # If GPU 2 (index 2) is available\n",
    "            print(\"Using GPU 2\")\n",
    "            return torch.device('cuda:2')\n",
    "        elif n_gpu > 0:  # If any GPU is available\n",
    "            print(f\"GPU 2 not available, using GPU 0\")\n",
    "            return torch.device('cuda:0')\n",
    "    \n",
    "    print(\"No GPU available, using CPU\")\n",
    "    return torch.device('cpu')\n",
    "\n",
    "class RealEstateDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Custom dataset for real estate data with temporal sequence handling\n",
    "        \"\"\"\n",
    "        # Static features remain the same\n",
    "        self.static_features = torch.FloatTensor(\n",
    "            data[['latitude', 'longitude', 'neighbourhood_cleansed_encoded']].values\n",
    "        )\n",
    "        \n",
    "        # Temporal features - organize into groups\n",
    "        temporal_cols = [\n",
    "            # Time features\n",
    "            'DTF_day_of_week', 'DTF_month', 'DTF_is_weekend',\n",
    "            'DTF_season_sin', 'DTF_season_cos',\n",
    "            # Price history features\n",
    "            'price_lag_90d', 'price_lag_120d', 'price_lag_150d', 'price_lag_180d',\n",
    "            # Rolling window features - 30 days\n",
    "            'rolling_mean_30d', 'rolling_std_30d', 'rolling_max_30d', 'rolling_min_30d',\n",
    "            # Rolling window features - 60 days\n",
    "            'rolling_mean_60d', 'rolling_std_60d', 'rolling_max_60d', 'rolling_min_60d',\n",
    "            # Rolling window features - 90 days\n",
    "            'rolling_mean_90d', 'rolling_std_90d', 'rolling_max_90d', 'rolling_min_90d'\n",
    "        ]\n",
    "        \n",
    "        # Get temporal data\n",
    "        temp_data = data[temporal_cols].values\n",
    "        \n",
    "        # Instead of reshaping, we'll keep the temporal features flat for now\n",
    "        self.temporal_features = torch.FloatTensor(temp_data)\n",
    "        \n",
    "        # Target\n",
    "        self.price = torch.FloatTensor(data['price'].values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.price)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'static': self.static_features[idx],\n",
    "            'temporal': self.temporal_features[idx],\n",
    "            'price': self.price[idx]\n",
    "        }\n",
    "\n",
    "class RealEstateNN(nn.Module):\n",
    "    def __init__(self, feature_dims):\n",
    "        \"\"\"\n",
    "        Neural network model with GRU for temporal features\n",
    "        \"\"\"\n",
    "        super(RealEstateNN, self).__init__()\n",
    "        \n",
    "        # Static features branch remains similar\n",
    "        self.static_branch = nn.Sequential(\n",
    "            nn.Linear(feature_dims['static'], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Temporal features processing\n",
    "        self.temporal_branch = nn.Sequential(\n",
    "            nn.Linear(feature_dims['temporal'], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Combined layers\n",
    "        combined_dim = 32 + 32  # Static + Temporal\n",
    "        self.combined_layers = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, static, temporal):\n",
    "        # Process static features\n",
    "        static_out = self.static_branch(static)\n",
    "        \n",
    "        # Process temporal features\n",
    "        temporal_out = self.temporal_branch(temporal)\n",
    "        \n",
    "        # Combine branches\n",
    "        combined = torch.cat([static_out, temporal_out], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        return self.combined_layers(combined)\n",
    "\n",
    "class RealEstateTrainer:\n",
    "    def __init__(self, feature_dims, device='cuda:2'):\n",
    "        \"\"\"\n",
    "        Trainer class for the real estate neural network\n",
    "        \"\"\"\n",
    "        self.device = torch.device(device)\n",
    "        self.model = RealEstateNN(feature_dims).to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"\n",
    "        Train for one epoch\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            # Move batch to GPU\n",
    "            static = batch['static'].to(self.device)\n",
    "            temporal = batch['temporal'].to(self.device)\n",
    "            price = batch['price'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(static, temporal)\n",
    "            loss = self.criterion(output.squeeze(), price)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        return total_loss / len(train_loader)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self, val_loader):\n",
    "        \"\"\"\n",
    "        Validate the model\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in val_loader:\n",
    "            # Move batch to GPU\n",
    "            static = batch['static'].to(self.device)\n",
    "            temporal = batch['temporal'].to(self.device)\n",
    "            price = batch['price'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = self.model(static, temporal)\n",
    "            loss = self.criterion(output.squeeze(), price)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        return total_loss / len(val_loader)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self, test_loader):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            # Move batch to GPU\n",
    "            static = batch['static'].to(self.device)\n",
    "            temporal = batch['temporal'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = self.model(static, temporal)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "            \n",
    "        return np.concatenate(predictions).squeeze()\n",
    "\n",
    "def train_model(train_data, val_data, batch_size=32, epochs=100, device='cuda:2'):\n",
    "    \"\"\"\n",
    "    Main training function with streamlined progress display\n",
    "    \"\"\"\n",
    "    # Create datasets\n",
    "    train_dataset = RealEstateDataset(train_data)\n",
    "    val_dataset = RealEstateDataset(val_data)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize feature dimensions\n",
    "    feature_dims = {\n",
    "        'static': 3,  # latitude, longitude, neighbourhood\n",
    "        'temporal': 21  # all temporal features\n",
    "    }\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = RealEstateTrainer(feature_dims, device)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Progress bar for epochs\n",
    "    pbar = tqdm(range(epochs), desc='Training')\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        # Training phase\n",
    "        train_loss = trainer.train_epoch(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss = trainer.validate(val_loader)\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'train_loss': f'{train_loss:.4f}',\n",
    "            'val_loss': f'{val_loss:.4f}',\n",
    "            'patience': f'{patience_counter}/{patience}'\n",
    "        })\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(trainer.model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"\\nEarly stopping triggered!\")\n",
    "                break\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Data loaded successfully.\n",
      "Reduced the number of listings to 2000 for testing and development.\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "train_data = pd.read_csv(r'C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\train_data_2024.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\test_data_2025.csv')\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# Reduce the number of listings to 500 for testing and development\n",
    "train_data = train_data.sample(n=2000, random_state=42)\n",
    "test_data = test_data.sample(n=2000, random_state=42)\n",
    "print(\"Reduced the number of listings to 2000 for testing and development.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 2 not available, using GPU 0\n",
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 20/100 [00:04<00:19,  4.10it/s, train_loss=0.0322, val_loss=0.0120, patience=9/10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping triggered!\n",
      "\n",
      "=== Evaluating Model ===\n",
      "Creating test dataset and loader...\n",
      "Making predictions...\n",
      "\n",
      "=== Final Model Performance ===\n",
      "RMSE: 0.1099\n",
      "MAE: 0.0700\n",
      "R2: 0.9902\n",
      "MAPE: 20.7810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the appropriate device\n",
    "device = get_device()\n",
    "\n",
    "# Train model\n",
    "print(\"\\nStarting model training...\")\n",
    "trainer = train_model(train_data, test_data, device=device)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluating Model ===\")\n",
    "print(\"Creating test dataset and loader...\")\n",
    "test_dataset = RealEstateDataset(test_data)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "predictions = trainer.predict(test_loader)\n",
    "\n",
    "# Calculate metrics\n",
    "true_prices = test_data['price'].values\n",
    "metrics = {\n",
    "    'rmse': np.sqrt(mean_squared_error(true_prices, predictions)),\n",
    "    'mae': mean_absolute_error(true_prices, predictions),\n",
    "    'r2': r2_score(true_prices, predictions),\n",
    "    'mape': np.mean(np.abs((true_prices - predictions) / true_prices)) * 100\n",
    "}\n",
    "\n",
    "print(\"\\n=== Final Model Performance ===\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric.upper()}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
