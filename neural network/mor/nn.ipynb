{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1 GPUs:\n",
      "GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "Selecting NVIDIA GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Using device: cuda:0\n",
      "\n",
      "Preparing data...\n",
      "\n",
      "Starting data preparation...\n",
      "Loading listings data...\n",
      "Loading calendar data...\n",
      "\n",
      "Initial data statistics:\n",
      "Total listings: 500\n",
      "Total records: 339131\n",
      "\n",
      "Processing dates...\n",
      "Cleaning price data...\n",
      "Missing prices: 0\n",
      "Sorting data...\n",
      "\n",
      "Creating features...\n",
      "Adding listing features...\n",
      "\n",
      "Scaling features...\n",
      "Scaling targets...\n",
      "\n",
      "Converting to tensors...\n",
      "\n",
      "Tensor shapes:\n",
      "Features: torch.Size([339131, 8])\n",
      "Targets: torch.Size([339131, 1])\n",
      "\n",
      "Checking data continuity...\n",
      "Warning: Data has gaps between dates\n",
      "\n",
      "Dataset created with 339095 samples\n",
      "Lookback: 30, Forecast horizon: 7\n",
      "\n",
      "Creating data loaders...\n",
      "\n",
      "Initializing model...\n",
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - 52.6s\n",
      "Train Loss: 0.1398, Val Loss: 0.1057\n",
      "New best model saved (Val Loss: 0.1057)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] - 52.6s\n",
      "Train Loss: 0.0590, Val Loss: 0.0511\n",
      "New best model saved (Val Loss: 0.0511)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] - 52.2s\n",
      "Train Loss: 0.0494, Val Loss: 0.0501\n",
      "New best model saved (Val Loss: 0.0501)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] - 78.0s\n",
      "Train Loss: 0.0472, Val Loss: 0.0837\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] - 77.5s\n",
      "Train Loss: 0.0444, Val Loss: 0.0438\n",
      "New best model saved (Val Loss: 0.0438)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] - 64.1s\n",
      "Train Loss: 0.0423, Val Loss: 0.0409\n",
      "New best model saved (Val Loss: 0.0409)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] - 68.3s\n",
      "Train Loss: 0.0392, Val Loss: 0.0343\n",
      "New best model saved (Val Loss: 0.0343)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] - 59.8s\n",
      "Train Loss: 0.0376, Val Loss: 0.0370\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 420\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 397\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInitializing model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    388\u001b[0m model \u001b[38;5;241m=\u001b[39m STRAPModel(\n\u001b[0;32m    389\u001b[0m     input_dim\u001b[38;5;241m=\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    390\u001b[0m     hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m     forecast_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m\n\u001b[0;32m    395\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 397\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSaving final model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    407\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m: history,\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m: target_scaler\n\u001b[0;32m    411\u001b[0m }, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 285\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, num_epochs, learning_rate, device)\u001b[0m\n\u001b[0;32m    282\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m--> 285\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[0;32m    288\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[2], line 127\u001b[0m, in \u001b[0;36mSTRAPModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Process through STRAP layers\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrap_layers:\n\u001b[1;32m--> 127\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Global average pooling over temporal dimension\u001b[39;00m\n\u001b[0;32m    130\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch_size, hidden_dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[2], line 98\u001b[0m, in \u001b[0;36mSTRAPBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     97\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_projection(x)\n\u001b[1;32m---> 98\u001b[0m     attended, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attended))\n\u001b[0;32m    100\u001b[0m     ff_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(x)\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1343\u001b[0m         query,\n\u001b[0;32m   1344\u001b[0m         key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\torch\\nn\\functional.py:6246\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   6243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   6244\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m dropout(attn_output_weights, p\u001b[38;5;241m=\u001b[39mdropout_p)\n\u001b[1;32m-> 6246\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6248\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   6249\u001b[0m     attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(tgt_len \u001b[38;5;241m*\u001b[39m bsz, embed_dim)\n\u001b[0;32m   6250\u001b[0m )\n\u001b[0;32m   6251\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First, import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Tuple, Dict, List\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Then import sklearn before torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Now import torch and its modules\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Finally import cuda specific modules\n",
    "from torch.cuda import amp\n",
    "\n",
    "def select_gpu():\n",
    "    \"\"\"Select the NVIDIA GPU if available.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Get number of GPUs\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"\\nFound {gpu_count} GPUs:\")\n",
    "        \n",
    "        # Find NVIDIA GPU\n",
    "        for i in range(gpu_count):\n",
    "            gpu_properties = torch.cuda.get_device_properties(i)\n",
    "            print(f\"GPU {i}: {gpu_properties.name}\")\n",
    "            \n",
    "            if 'NVIDIA' in gpu_properties.name:\n",
    "                print(f\"\\nSelecting NVIDIA GPU: {gpu_properties.name}\")\n",
    "                torch.cuda.set_device(i)\n",
    "                return torch.device(f'cuda:{i}')\n",
    "    \n",
    "    print(\"\\nNo NVIDIA GPU found, using CPU\")\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def get_gpu_info():\n",
    "    \"\"\"Print GPU information if available.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_properties = torch.cuda.get_device_properties(i)\n",
    "            print(f\"\\nGPU {i}: {gpu_properties.name}\")\n",
    "            print(f\"Memory: {gpu_properties.total_memory / 1024**3:.2f} GB\")\n",
    "            print(f\"CUDA Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n",
    "    else:\n",
    "        print(\"\\nNo GPU available, using CPU\")\n",
    "\n",
    "class TemporalFeatureDataset(Dataset):\n",
    "    \"\"\"Dataset class with minimal output.\"\"\"\n",
    "    def __init__(self, features, targets, lookback=30, forecast_horizon=7):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.lookback = lookback\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        \n",
    "        # Calculate valid indices\n",
    "        self.valid_indices = len(features) - lookback - forecast_horizon + 1\n",
    "        \n",
    "        # Print only once during initialization\n",
    "        print(f\"\\nDataset created with {self.valid_indices} samples\")\n",
    "        print(f\"Lookback: {lookback}, Forecast horizon: {forecast_horizon}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.valid_indices\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= self.valid_indices:\n",
    "            raise IndexError(f\"Index {idx} out of bounds\")\n",
    "            \n",
    "        x = self.features[idx:idx + self.lookback]\n",
    "        y = self.targets[idx + self.lookback:idx + self.lookback + self.forecast_horizon]\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "class STRAPBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "        )\n",
    "        self.input_projection = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)\n",
    "        attended, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attended))\n",
    "        ff_out = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_out))\n",
    "        return x\n",
    "\n",
    "class STRAPModel(nn.Module):\n",
    "    \"\"\"Modified STRAP model with explicit shape handling.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, num_heads=4, \n",
    "                 dropout=0.1, forecast_horizon=7):\n",
    "        super().__init__()\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        \n",
    "        self.strap_layers = nn.ModuleList([\n",
    "            STRAPBlock(input_dim if i == 0 else hidden_dim,\n",
    "                      hidden_dim,\n",
    "                      num_heads,\n",
    "                      dropout)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, forecast_horizon)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, lookback, features)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Process through STRAP layers\n",
    "        for layer in self.strap_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Global average pooling over temporal dimension\n",
    "        x = torch.mean(x, dim=1)  # Shape: (batch_size, hidden_dim)\n",
    "        \n",
    "        # Project to forecast horizon\n",
    "        x = self.output_layer(x)  # Shape: (batch_size, forecast_horizon)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def clean_price(price_series):\n",
    "    \"\"\"Clean price data without type checking.\"\"\"\n",
    "    try:\n",
    "        if isinstance(price_series.iloc[0], str):\n",
    "            return pd.to_numeric(price_series.str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "        return pd.to_numeric(price_series, errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning prices: {e}\")\n",
    "        return pd.to_numeric(price_series, errors='coerce')\n",
    "\n",
    "def prepare_data(calendar_path, listings_path, n_listings=500):\n",
    "    \"\"\"Modified prepare_data function with additional checks.\"\"\"\n",
    "    print(\"\\nStarting data preparation...\")\n",
    "    \n",
    "    try:\n",
    "        # Load listings data\n",
    "        print(\"Loading listings data...\")\n",
    "        listings_df = pd.read_csv(listings_path)\n",
    "        sampled_listings = listings_df['id'].sample(n=n_listings, random_state=42)\n",
    "        \n",
    "        # Load calendar data\n",
    "        print(\"Loading calendar data...\")\n",
    "        calendar_df = pd.read_csv(calendar_path)\n",
    "        calendar_df = calendar_df[calendar_df['listing_id'].isin(sampled_listings)]\n",
    "        \n",
    "        print(f\"\\nInitial data statistics:\")\n",
    "        print(f\"Total listings: {len(sampled_listings)}\")\n",
    "        print(f\"Total records: {len(calendar_df)}\")\n",
    "        \n",
    "        # Convert dates\n",
    "        print(\"\\nProcessing dates...\")\n",
    "        calendar_df['date'] = pd.to_datetime(calendar_df['date'])\n",
    "        \n",
    "        # Clean prices\n",
    "        print(\"Cleaning price data...\")\n",
    "        if isinstance(calendar_df['price'].iloc[0], str):\n",
    "            calendar_df['price_numeric'] = pd.to_numeric(\n",
    "                calendar_df['price'].str.replace('$', '').str.replace(',', ''), \n",
    "                errors='coerce'\n",
    "            )\n",
    "        else:\n",
    "            calendar_df['price_numeric'] = calendar_df['price']\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_prices = calendar_df['price_numeric'].isna().sum()\n",
    "        print(f\"Missing prices: {missing_prices}\")\n",
    "        \n",
    "        # Remove invalid prices\n",
    "        calendar_df = calendar_df.dropna(subset=['price_numeric'])\n",
    "        \n",
    "        # Sort by listing and date\n",
    "        print(\"Sorting data...\")\n",
    "        calendar_df = calendar_df.sort_values(['listing_id', 'date'])\n",
    "        \n",
    "        # Create features\n",
    "        print(\"\\nCreating features...\")\n",
    "        calendar_df['day_of_week'] = calendar_df['date'].dt.dayofweek\n",
    "        calendar_df['month'] = calendar_df['date'].dt.month\n",
    "        calendar_df['day_of_year'] = calendar_df['date'].dt.dayofyear\n",
    "        calendar_df['is_weekend'] = calendar_df['day_of_week'].isin([5, 6]).astype(int)\n",
    "        calendar_df['week_of_year'] = calendar_df['date'].dt.isocalendar().week\n",
    "        \n",
    "        # Merge with listings\n",
    "        print(\"Adding listing features...\")\n",
    "        calendar_df = pd.merge(\n",
    "            calendar_df,\n",
    "            listings_df[['id', 'latitude', 'longitude']],\n",
    "            left_on='listing_id',\n",
    "            right_on='id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Define features\n",
    "        feature_cols = [\n",
    "            'price_numeric', \n",
    "            'day_of_week', \n",
    "            'month', \n",
    "            'day_of_year',\n",
    "            'week_of_year',\n",
    "            'is_weekend',\n",
    "            'latitude',\n",
    "            'longitude'\n",
    "        ]\n",
    "        \n",
    "        # Scale features\n",
    "        print(\"\\nScaling features...\")\n",
    "        feature_scaler = StandardScaler()\n",
    "        features_scaled = feature_scaler.fit_transform(calendar_df[feature_cols])\n",
    "        \n",
    "        # Scale targets\n",
    "        print(\"Scaling targets...\")\n",
    "        target_scaler = StandardScaler()\n",
    "        targets_scaled = target_scaler.fit_transform(calendar_df['price_numeric'].values.reshape(-1, 1))\n",
    "        \n",
    "        # Convert to tensors\n",
    "        print(\"\\nConverting to tensors...\")\n",
    "        features_tensor = torch.FloatTensor(features_scaled)\n",
    "        targets_tensor = torch.FloatTensor(targets_scaled)\n",
    "        \n",
    "        print(\"\\nTensor shapes:\")\n",
    "        print(f\"Features: {features_tensor.shape}\")\n",
    "        print(f\"Targets: {targets_tensor.shape}\")\n",
    "        \n",
    "        # Verify data is properly ordered\n",
    "        print(\"\\nChecking data continuity...\")\n",
    "        date_diffs = calendar_df.groupby('listing_id')['date'].diff().dt.days\n",
    "        if date_diffs.max() > 1:\n",
    "            print(\"Warning: Data has gaps between dates\")\n",
    "        \n",
    "        return features_tensor, targets_tensor, target_scaler\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in data preparation: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, learning_rate, device):\n",
    "    \"\"\"Training function with cleaner output.\"\"\"\n",
    "    print(\"\\nStarting model training...\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': [], 'epoch_times': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        # Update tqdm to refresh less frequently\n",
    "        train_progress = tqdm(\n",
    "            train_loader, \n",
    "            desc=f'Epoch {epoch+1}/{num_epochs} [Train]',\n",
    "            ncols=100,  # Fixed width\n",
    "            mininterval=1.0,  # Update every second\n",
    "            leave=False  # Don't leave progress bars\n",
    "        )\n",
    "        \n",
    "        for batch_x, batch_y in train_progress:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with amp.autocast():\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_progress = tqdm(\n",
    "                val_loader, \n",
    "                desc=f'Epoch {epoch+1}/{num_epochs} [Val]',\n",
    "                ncols=100,\n",
    "                mininterval=1.0,\n",
    "                leave=False\n",
    "            )\n",
    "            \n",
    "            for batch_x, batch_y in val_progress:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                \n",
    "                with amp.autocast():\n",
    "                    outputs = model(batch_x)\n",
    "                    val_loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['epoch_times'].append(epoch_time)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] - {epoch_time:.1f}s')\n",
    "        print(f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "            }, 'best_model.pth')\n",
    "            print(f'New best model saved (Val Loss: {best_val_loss:.4f})')\n",
    "        \n",
    "        print('-' * 60)  # Add separator between epochs\n",
    "    \n",
    "    return history\n",
    "\n",
    "def main():\n",
    "    device = select_gpu()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nPreparing data...\")\n",
    "        features, targets, target_scaler = prepare_data(\n",
    "            r'C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\data_new\\paris\\paris_merged_calendar.csv',\n",
    "            r'C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\data_new\\paris\\2024-06-10\\listings.csv'\n",
    "        )\n",
    "        \n",
    "        dataset = TemporalFeatureDataset(\n",
    "            features, \n",
    "            targets,\n",
    "            lookback=30,\n",
    "            forecast_horizon=7\n",
    "        )\n",
    "        \n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        \n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            dataset, \n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        \n",
    "        print(\"\\nCreating data loaders...\")\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=32,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        print(\"\\nInitializing model...\")\n",
    "        model = STRAPModel(\n",
    "            input_dim=features.shape[1],\n",
    "            hidden_dim=128,\n",
    "            num_layers=2,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            forecast_horizon=7\n",
    "        ).to(device)\n",
    "        \n",
    "        history = train_model(\n",
    "            model, \n",
    "            train_loader, \n",
    "            val_loader, \n",
    "            num_epochs=100,\n",
    "            learning_rate=1e-4,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        print(\"\\nSaving final model...\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'history': history,\n",
    "            'scaler': target_scaler\n",
    "        }, 'final_model.pth')\n",
    "        \n",
    "        print(\"Training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in execution: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
