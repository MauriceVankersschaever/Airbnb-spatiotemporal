{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "import seaborn as sns\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from sklearn.neighbors import BallTree\n",
    "import math\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        # Get the number of available GPUs\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "        print(f\"Number of GPUs available: {n_gpu}\")\n",
    "        \n",
    "        if n_gpu >= 3:  # If GPU 2 (index 2) is available\n",
    "            print(\"Using GPU 2\")\n",
    "            return torch.device('cuda:2')\n",
    "        elif n_gpu > 0:  # If any GPU is available\n",
    "            print(f\"GPU 2 not available, using GPU 0\")\n",
    "            return torch.device('cuda:0')\n",
    "    \n",
    "    print(\"No GPU available, using CPU\")\n",
    "    return torch.device('cpu')\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatial attention mechanism based on geographical features\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        weights = self.attention(x)\n",
    "        return x * weights\n",
    "\n",
    "class TemporalEncoder(nn.Module):\n",
    "    def __init__(self, price_history_dim, rolling_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Price history processing\n",
    "        self.price_history_gru = nn.GRU(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "        # Rolling window processing\n",
    "        self.rolling_encoder = nn.Sequential(\n",
    "            nn.Linear(rolling_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        \n",
    "        # Attention for combining temporal features\n",
    "        self.temporal_attention = nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, price_history, rolling_features):\n",
    "        # Process price history\n",
    "        price_history = price_history.unsqueeze(-1)  # Add feature dimension\n",
    "        _, price_hidden = self.price_history_gru(price_history)\n",
    "        price_encoding = price_hidden[-1]\n",
    "        \n",
    "        # Process rolling features\n",
    "        rolling_encoding = self.rolling_encoder(rolling_features)\n",
    "        \n",
    "        # Combine using attention\n",
    "        combined = torch.cat([price_encoding, rolling_encoding], dim=-1)\n",
    "        attention_weights = torch.softmax(self.temporal_attention(combined), dim=-1)\n",
    "        \n",
    "        temporal_embedding = (\n",
    "            attention_weights[:, 0:1] * price_encoding +\n",
    "            attention_weights[:, 1:2] * rolling_encoding\n",
    "        )\n",
    "        \n",
    "        return temporal_embedding\n",
    "\n",
    "class EnhancedRealEstateTrainer:\n",
    "    def __init__(self, feature_dims, device='cuda:2'):\n",
    "        self.device = torch.device(device)\n",
    "        self.model = EnhancedRealEstateNN(feature_dims).to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            # Move batch to GPU\n",
    "            basic_spatial = batch['basic_spatial'].to(self.device)\n",
    "            enhanced_spatial = batch['enhanced_spatial'].to(self.device)\n",
    "            time = batch['time'].to(self.device)\n",
    "            price_history = batch['price_history'].to(self.device)\n",
    "            rolling = batch['rolling'].to(self.device)\n",
    "            price = batch['price'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(basic_spatial, enhanced_spatial, time, price_history, rolling)\n",
    "            loss = self.criterion(output.squeeze(), price)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        return total_loss / len(train_loader)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self, val_loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in val_loader:\n",
    "            # Move batch to GPU\n",
    "            basic_spatial = batch['basic_spatial'].to(self.device)\n",
    "            enhanced_spatial = batch['enhanced_spatial'].to(self.device)\n",
    "            time = batch['time'].to(self.device)\n",
    "            price_history = batch['price_history'].to(self.device)\n",
    "            rolling = batch['rolling'].to(self.device)\n",
    "            price = batch['price'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = self.model(basic_spatial, enhanced_spatial, time, price_history, rolling)\n",
    "            loss = self.criterion(output.squeeze(), price)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        return total_loss / len(val_loader)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self, test_loader):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            # Move batch to GPU\n",
    "            basic_spatial = batch['basic_spatial'].to(self.device)\n",
    "            enhanced_spatial = batch['enhanced_spatial'].to(self.device)\n",
    "            time = batch['time'].to(self.device)\n",
    "            price_history = batch['price_history'].to(self.device)\n",
    "            rolling = batch['rolling'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = self.model(basic_spatial, enhanced_spatial, time, price_history, rolling)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "            \n",
    "        return np.concatenate(predictions).squeeze()\n",
    "\n",
    "def train_enhanced_model(train_data, val_data, batch_size=32, epochs=100, device='cuda:2'):\n",
    "    \"\"\"\n",
    "    Main training function for enhanced model\n",
    "    \"\"\"\n",
    "    # Create datasets\n",
    "    train_dataset = EnhancedRealEstateDataset(train_data)\n",
    "    val_dataset = EnhancedRealEstateDataset(val_data)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize feature dimensions\n",
    "    feature_dims = {\n",
    "        'basic_spatial': 3,      # latitude, longitude, neighbourhood\n",
    "        'enhanced_spatial': 8,   # new spatial features\n",
    "        'time': 5,              # time-related features\n",
    "        'price_history': 4,     # price history features\n",
    "        'rolling': 12           # rolling window features\n",
    "    }\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = EnhancedRealEstateTrainer(feature_dims, device)\n",
    "    \n",
    "    # Training loop with early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    pbar = tqdm(range(epochs), desc='Training Enhanced Model')\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        train_loss = trainer.train_epoch(train_loader)\n",
    "        val_loss = trainer.validate(val_loader)\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'train_loss': f'{train_loss:.4f}',\n",
    "            'val_loss': f'{val_loss:.4f}',\n",
    "            'patience': f'{patience_counter}/{patience}'\n",
    "        })\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(trainer.model.state_dict(), 'best_enhanced_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"\\nEarly stopping triggered!\")\n",
    "                break\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "class EnhancedRealEstateDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Enhanced dataset handling both original and new spatial features\n",
    "        Args:\n",
    "            data: DataFrame with combined features\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Original spatial features\n",
    "        self.basic_spatial = torch.FloatTensor(\n",
    "            data[['latitude', 'longitude', 'neighbourhood_cleansed_encoded']].values\n",
    "        )\n",
    "        \n",
    "        # New spatial features from create_spatial_features\n",
    "        self.enhanced_spatial = torch.FloatTensor(data[[\n",
    "            'distance_to_center', 'north_south', 'knn_price_mean',\n",
    "            'knn_price_std', 'price_diff_from_neighbors', 'knn_price_median',\n",
    "            'knn_price_range', 'distance_weighted_price'\n",
    "        ]].values)\n",
    "        \n",
    "        # Time features\n",
    "        self.time_features = torch.FloatTensor(data[[\n",
    "            'DTF_day_of_week', 'DTF_month', 'DTF_is_weekend',\n",
    "            'DTF_season_sin', 'DTF_season_cos'\n",
    "        ]].values)\n",
    "        \n",
    "        # Price history features\n",
    "        self.price_history = torch.FloatTensor(data[[\n",
    "            'price_lag_90d', 'price_lag_120d', \n",
    "            'price_lag_150d', 'price_lag_180d'\n",
    "        ]].values)\n",
    "        \n",
    "        # Rolling window features\n",
    "        self.rolling_features = torch.FloatTensor(data[[\n",
    "            'rolling_mean_30d', 'rolling_std_30d', 'rolling_max_30d', 'rolling_min_30d',\n",
    "            'rolling_mean_60d', 'rolling_std_60d', 'rolling_max_60d', 'rolling_min_60d',\n",
    "            'rolling_mean_90d', 'rolling_std_90d', 'rolling_max_90d', 'rolling_min_90d'\n",
    "        ]].values)\n",
    "        \n",
    "        # Target\n",
    "        self.price = torch.FloatTensor(data['price'].values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.price)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'basic_spatial': self.basic_spatial[idx],\n",
    "            'enhanced_spatial': self.enhanced_spatial[idx],\n",
    "            'time': self.time_features[idx],\n",
    "            'price_history': self.price_history[idx],\n",
    "            'rolling': self.rolling_features[idx],\n",
    "            'price': self.price[idx]\n",
    "        }\n",
    "\n",
    "class EnhancedSpatialEncoder(nn.Module):\n",
    "    def __init__(self, basic_dim, enhanced_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Process basic spatial features\n",
    "        self.basic_encoder = nn.Sequential(\n",
    "            nn.Linear(basic_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Process enhanced spatial features\n",
    "        self.enhanced_encoder = nn.Sequential(\n",
    "            nn.Linear(enhanced_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(96, 32),  # 32 + 64 from both encoders\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2),  # 2 attention weights\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Final fusion\n",
    "        self.fusion = nn.Linear(96, 32)\n",
    "        \n",
    "    def forward(self, basic_spatial, enhanced_spatial):\n",
    "        # Encode both types of features\n",
    "        basic_encoded = self.basic_encoder(basic_spatial)\n",
    "        enhanced_encoded = self.enhanced_encoder(enhanced_spatial)\n",
    "        \n",
    "        # Concatenate for attention\n",
    "        combined = torch.cat([basic_encoded, enhanced_encoded], dim=1)\n",
    "        \n",
    "        # Calculate attention weights\n",
    "        weights = self.attention(combined)\n",
    "        \n",
    "        # Apply attention and fuse\n",
    "        attended = torch.cat([\n",
    "            basic_encoded * weights[:, 0:1],\n",
    "            enhanced_encoded * weights[:, 1:2]\n",
    "        ], dim=1)\n",
    "        \n",
    "        return self.fusion(attended)\n",
    "\n",
    "class EnhancedRealEstateNN(nn.Module):\n",
    "    def __init__(self, feature_dims):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Enhanced spatial processing\n",
    "        self.spatial_encoder = EnhancedSpatialEncoder(\n",
    "            basic_dim=feature_dims['basic_spatial'],\n",
    "            enhanced_dim=feature_dims['enhanced_spatial']\n",
    "        )\n",
    "        \n",
    "        # Other components remain the same\n",
    "        self.time_encoder = nn.Sequential(\n",
    "            nn.Linear(feature_dims['time'], 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        \n",
    "        self.temporal_encoder = TemporalEncoder(\n",
    "            price_history_dim=feature_dims['price_history'],\n",
    "            rolling_dim=feature_dims['rolling']\n",
    "        )\n",
    "        \n",
    "        # Final layers\n",
    "        combined_dim = 32 + 16 + 32  # spatial + time + temporal\n",
    "        self.final_layers = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, basic_spatial, enhanced_spatial, time, price_history, rolling):\n",
    "        # Process all features\n",
    "        spatial_encoding = self.spatial_encoder(basic_spatial, enhanced_spatial)\n",
    "        time_encoding = self.time_encoder(time)\n",
    "        temporal_encoding = self.temporal_encoder(price_history, rolling)\n",
    "        \n",
    "        # Combine all features\n",
    "        combined = torch.cat([\n",
    "            spatial_encoding,\n",
    "            time_encoding,\n",
    "            temporal_encoding\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        return self.final_layers(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate the distance between two points using the Haversine formula.\"\"\"\n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "def create_spatial_features(df, k_neighbors=5, chunk_size=1000, n_jobs=-1):\n",
    "    \"\"\"Enhanced spatial features while maintaining existing structure\"\"\"\n",
    "    city_center_lat, city_center_lon = 48.8566, 2.3522\n",
    "    \n",
    "    # Keep existing spatial features\n",
    "    spatial_data = {\n",
    "        'distance_to_center': [],\n",
    "        'north_south': [],\n",
    "        'knn_price_mean': [],\n",
    "        'knn_price_std': [],\n",
    "        'price_diff_from_neighbors': []\n",
    "    }\n",
    "    \n",
    "    # Add new spatial features\n",
    "    spatial_data.update({\n",
    "        'knn_price_median': [],  # Add median as more robust metric\n",
    "        'knn_price_range': [],   # Add price range in neighborhood\n",
    "        'distance_weighted_price': []  # Add distance-weighted price\n",
    "    })\n",
    "    \n",
    "    # Calculate basic distance features (keeping existing logic)\n",
    "    spatial_data['distance_to_center'] = df.apply(\n",
    "        lambda row: calculate_distance(\n",
    "            row['latitude'], \n",
    "            row['longitude'], \n",
    "            city_center_lat, \n",
    "            city_center_lon\n",
    "        ),\n",
    "        axis=1\n",
    "    ).values\n",
    "    \n",
    "    spatial_data['north_south'] = (df['latitude'] - city_center_lat).values\n",
    "    \n",
    "    # Enhanced BallTree processing\n",
    "    all_coords = np.radians(df[['latitude', 'longitude']].values)\n",
    "    tree = BallTree(all_coords, metric='haversine')\n",
    "    all_prices = df['price'].values\n",
    "    \n",
    "    def enhanced_process_chunk(chunk_data, tree, k_neighbors, all_prices):\n",
    "        \"\"\"Enhanced chunk processing with additional metrics\"\"\"\n",
    "        coords = np.radians(chunk_data[['latitude', 'longitude']].values)\n",
    "        distances, indices = tree.query(coords, k=k_neighbors + 1)\n",
    "        \n",
    "        # Convert distances to weights (inverse distance weighting)\n",
    "        weights = 1 / (distances[:, 1:] + 1e-6)  # Add small epsilon to avoid division by zero\n",
    "        weights = weights / weights.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        neighbor_prices = np.take(all_prices, indices[:, 1:])\n",
    "        \n",
    "        return {\n",
    "            'knn_price_mean': np.nanmean(neighbor_prices, axis=1),\n",
    "            'knn_price_std': np.nanstd(neighbor_prices, axis=1),\n",
    "            'knn_price_median': np.nanmedian(neighbor_prices, axis=1),\n",
    "            'knn_price_range': np.ptp(neighbor_prices, axis=1),\n",
    "            'price_diff_from_neighbors': chunk_data['price'].values - np.nanmean(neighbor_prices, axis=1),\n",
    "            'distance_weighted_price': np.sum(weights * neighbor_prices, axis=1)\n",
    "        }\n",
    "    \n",
    "    # Split and process chunks (keeping existing logic)\n",
    "    n_chunks = math.ceil(len(df) / chunk_size)\n",
    "    chunks = np.array_split(df, n_chunks)\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(enhanced_process_chunk)(\n",
    "            chunk, \n",
    "            tree, \n",
    "            k_neighbors,\n",
    "            all_prices\n",
    "        ) for chunk in chunks\n",
    "    )\n",
    "    \n",
    "    # Combine results with new features\n",
    "    for key in spatial_data.keys():\n",
    "        if key not in ['distance_to_center', 'north_south']:\n",
    "            spatial_data[key] = np.concatenate([r[key] for r in results])\n",
    "    \n",
    "    spatial_features = pd.DataFrame(spatial_data, index=df.index)\n",
    "    \n",
    "    # Enhanced feature standardization\n",
    "    features_to_standardize = list(spatial_data.keys())\n",
    "    \n",
    "    for col in features_to_standardize:\n",
    "        spatial_features[col] = (spatial_features[col] - spatial_features[col].mean()) / spatial_features[col].std()\n",
    "    \n",
    "    return spatial_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Data loaded successfully.\n",
      "Reduced to 500 training listings and 500 test listings\n",
      "Training data shape: (172430, 27)\n",
      "Test data shape: (30500, 27)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "train_data = pd.read_csv(r'C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\train_data_2024.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\mvk\\Documents\\DATA_school\\thesis\\test_data_2025.csv')\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# Reduce the number of unique listings for testing and development\n",
    "n_train_listings = 500 \n",
    "n_test_listings = 500\n",
    "\n",
    "# Get random sample of unique listing IDs\n",
    "train_listings = train_data['listing_id'].unique()\n",
    "np.random.seed(42)\n",
    "selected_train_listings = np.random.choice(train_listings, n_train_listings, replace=False)\n",
    "\n",
    "# Filter train data to keep all rows for selected listings\n",
    "train_data = train_data[train_data['listing_id'].isin(selected_train_listings)]\n",
    "\n",
    "# Do the same for test data\n",
    "test_listings = test_data['listing_id'].unique()\n",
    "selected_test_listings = np.random.choice(test_listings, n_test_listings, replace=False)\n",
    "test_data = test_data[test_data['listing_id'].isin(selected_test_listings)]\n",
    "\n",
    "print(f\"Reduced to {n_train_listings} training listings and {n_test_listings} test listings\")\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating spatial features for training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial features for training data created.\n",
      "Creating spatial features for test data...\n",
      "Spatial features for test data created.\n",
      "Combining spatial features with existing features...\n",
      "Features combined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Add spatial features\n",
    "print(\"Creating spatial features for training data...\")\n",
    "train_spatial = create_spatial_features(train_data)\n",
    "print(\"Spatial features for training data created.\")\n",
    "\n",
    "print(\"Creating spatial features for test data...\")\n",
    "test_spatial = create_spatial_features(test_data)\n",
    "print(\"Spatial features for test data created.\")\n",
    "\n",
    "# Combine with existing features\n",
    "print(\"Combining spatial features with existing features...\")\n",
    "X_train = pd.concat([train_data, train_spatial], axis=1)  # Keep all columns including price\n",
    "X_test = pd.concat([test_data, test_spatial], axis=1)  # Keep all columns including price\n",
    "print(\"Features combined.\")\n",
    "\n",
    "test_dates = pd.to_datetime(test_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting enhanced model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Enhanced Model:   9%|â–‰         | 9/100 [06:30<1:05:45, 43.36s/it, train_loss=0.0038, val_loss=nan, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping triggered!\n",
      "\n",
      "=== Evaluating Enhanced Model ===\n",
      "Creating test dataset and loader...\n",
      "Making predictions...\n"
     ]
    }
   ],
   "source": [
    "# Train enhanced model\n",
    "print(\"\\nStarting enhanced model training...\")\n",
    "trainer = train_enhanced_model(X_train, X_test, batch_size=32, epochs=100, device=device)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluating Enhanced Model ===\")\n",
    "print(\"Creating test dataset and loader...\")\n",
    "test_dataset = EnhancedRealEstateDataset(X_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "predictions = trainer.predict(test_loader)\n",
    "\n",
    "# Update metrics calculation\n",
    "true_prices = X_test['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m      2\u001b[0m true_prices \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_absolute_error(true_prices, predictions),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m: r2_score(true_prices, predictions),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs((true_prices \u001b[38;5;241m-\u001b[39m predictions) \u001b[38;5;241m/\u001b[39m true_prices)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Print traditional metrics\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Final Enhanced Model Performance ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mvk\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "true_prices = y_test.values\n",
    "metrics = {\n",
    "    'rmse': np.sqrt(mean_squared_error(true_prices, predictions)),\n",
    "    'mae': mean_absolute_error(true_prices, predictions),\n",
    "    'r2': r2_score(true_prices, predictions),\n",
    "    'mape': np.mean(np.abs((true_prices - predictions) / true_prices)) * 100\n",
    "}\n",
    "\n",
    "# Print traditional metrics\n",
    "print(\"\\n=== Final Enhanced Model Performance ===\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric.upper()}: {value:.4f}\")\n",
    "\n",
    "# Additional spatiotemporal analysis\n",
    "print(\"\\n=== Spatiotemporal Analysis ===\")\n",
    "\n",
    "# Analyze temporal performance\n",
    "monthly_performance = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(test_data['date']),\n",
    "    'True': true_prices,\n",
    "    'Predicted': predictions,\n",
    "    'AbsError': np.abs(true_prices - predictions)\n",
    "})\n",
    "monthly_errors = monthly_performance.groupby(monthly_performance['Date'].dt.strftime('%Y-%m'))[['AbsError']].agg(['mean', 'std'])\n",
    "print(\"\\nMonthly Error Analysis:\")\n",
    "print(monthly_errors)\n",
    "\n",
    "# Analyze spatial performance\n",
    "spatial_performance = pd.DataFrame({\n",
    "    'Neighborhood': test_data['neighbourhood_cleansed_encoded'],\n",
    "    'AbsError': np.abs(true_prices - predictions)\n",
    "})\n",
    "neighborhood_errors = spatial_performance.groupby('Neighborhood')[['AbsError']].agg(['mean', 'std', 'count'])\n",
    "print(\"\\nNeighborhood Error Analysis:\")\n",
    "print(neighborhood_errors)\n",
    "\n",
    "# Create visualization of errors over time and space\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Temporal error plot\n",
    "plt.subplot(1, 2, 1)\n",
    "monthly_performance.set_index('Date')['AbsError'].rolling(window=7).mean().plot()\n",
    "plt.title('7-Day Rolling Average of Absolute Error')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Absolute Error')\n",
    "\n",
    "# Spatial error plot\n",
    "plt.subplot(1, 2, 2)\n",
    "neighborhood_errors['AbsError']['mean'].sort_values().plot(kind='bar')\n",
    "plt.title('Mean Absolute Error by Neighborhood')\n",
    "plt.xlabel('Neighborhood')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model and predictions\n",
    "print(\"\\nSaving model and predictions...\")\n",
    "torch.save(trainer.model.state_dict(), 'enhanced_model_final.pth')\n",
    "np.save('enhanced_predictions.npy', predictions)\n",
    "\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Error Autocorrelation Analysis ===\n",
      "\n",
      "Error Autocorrelations:\n",
      "Lag 1 day(s): nan\n",
      "Lag 2 day(s): nan\n",
      "Lag 3 day(s): nan\n",
      "Lag 4 day(s): nan\n",
      "Lag 5 day(s): nan\n",
      "Lag 6 day(s): nan\n",
      "Lag 7 day(s): nan\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAHWCAYAAACblCSNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIAElEQVR4nO3de3zP9f//8ft77OQwc5qZxpxijml+TilhTIlWIktOiXw0fMzHp5SI+iQlZ+lTH6QP4kOlEjJnachEzt+Swyfa0JqNsc32/P3Ra+9Pb5vZeG/z5na9XHap9/P1fL3ej+fruXH32vP1etuMMUYAAAAA5FbUBQAAAAC3CsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQDcxl599VXZbDanHnPTpk2y2WzatGmTU48LALcCwjFwB/jwww9ls9mu+bV9+/aiLvG6evToIZvNphdeeOGmj/Xuu+/qww8/vPmibnN38nlatWqVXn31VacfNygo6Jo/h7Vr187X/m5ubvL19VXDhg01aNAg7dixw+n1AncimzHGFHURAArWhx9+qP79+2vChAmqXr16tu2dOnVShQoViqCyvElKSlKlSpXk7++vjIwMnThx4qauhjZo0EAVKlS4I658vvrqqxo/frxu5I/6a52nzMxMpaWlycPDQ25ut+c1lsjISM2ePfuGzltuVqxYoQsXLji0nThxQmPGjNGQIUM0e/bsXPcPCgpS2bJlNXLkSElScnKyDh06pGXLlikuLk4jRozQlClTnFozcKcpXtQFACg8Dz30kJo2bZqvfa5cuaLMzEx5eHhk23bx4kWVLFnyhusxxujy5cvy9vbOtd8nn3yijIwMzZs3T+3atdOWLVvUpk2bG37fW11W+PTy8sq27WbPuTO4ubnlWBuuLzw8PFvb66+/Lknq1atXno5RpUoVPf300w5tkyZN0lNPPaWpU6eqdu3a+stf/nLTtQJ3qtvzn/wAbsjx48dls9k0efJkTZs2TTVr1pSnp6cOHjxoX7t68OBBPfXUUypbtqxat24t6Y8A/dprr9n7BwUF6aWXXlJqaqrD8YOCgvTII4/o66+/VtOmTeXt7a1//vOf161r0aJF6tChg9q2bavg4GAtWrQoW59rra3NWlJy/Phxew0HDhzQ5s2b7b+efvDBB+39f/75Z3Xv3l3lypVTiRIl1KJFC3311VfZjnv58mW9+uqruvvuu+Xl5aXKlSvr8ccf19GjR+19Ll68qJEjRyowMFCenp6qU6eOJk+enO1qpM1mU2RkpBYtWqT69evL09NTa9assde+efNmDRkyRH5+frrrrrvs+61evVr333+/SpYsqdKlS6tz5846cODAdc/n/Pnz1a5dO/n5+cnT01P16tXTnDlzHPrkdp6uteZ42bJlCgkJkbe3typUqKCnn35ap06dcujTr18/lSpVSqdOnVJ4eLhKlSqlihUr6m9/+5syMjKuW7vNZstxuUNQUJD69etnf5117rZs2aLnnntO5cuXl4+Pj/r06aPff/891/fo16+f/Qrun5c9ZMnrvObV4sWLVb16dbVq1eqG9pckb29v/fvf/1a5cuX0j3/8w6GWyZMnq1WrVipfvry8vb0VEhKi5cuXO+zfpk0bNW7cOMdj16lTR2FhYfbXS5YsUUhIiEqXLi0fHx81bNhQ06dPv+HagVsNV46BO8j58+d17tw5hzabzaby5cs7tM2fP1+XL1/WoEGD5OnpqXLlytm3de/eXbVr19Ybb7xh/wv42Wef1YIFC/TEE09o5MiR2rFjhyZOnKhDhw7ps88+czj2kSNHFBERoeeee04DBw5UnTp1cq359OnT2rhxoxYsWCBJioiI0NSpUzVr1qwcr2Zfz7Rp0zR06FCVKlVKL7/8siSpUqVKkqT4+Hi1atVKKSkpGjZsmMqXL68FCxaoa9euWr58uR577DFJUkZGhh555BGtX79ePXv21PDhw5WcnKzo6Gjt379fNWvWlDFGXbt21caNGzVgwADdc889+vrrrzVq1CidOnVKU6dOdahrw4YN+s9//qPIyEhVqFBBQUFB2rNnjyRpyJAhqlixosaOHauLFy9Kkv7973+rb9++CgsL06RJk5SSkqI5c+aodevW+v777xUUFHTNczBnzhzVr19fXbt2VfHixfXll19qyJAhyszM1PPPP3/d85STrKU7/+///T9NnDhR8fHxmj59urZt26bvv/9evr6+9r4ZGRkKCwtT8+bNNXnyZK1bt07vvPOOatas6fQrnpGRkfL19dWrr76qI0eOaM6cOTpx4oQ94Ofkueee0+nTpxUdHa1///vfDtvyO6/X8/333+vQoUP2c3wzSpUqpccee0xz587VwYMHVb9+fUnS9OnT1bVrV/Xq1UtpaWlasmSJunfvrpUrV6pz586SpN69e2vgwIHav3+/GjRoYD/md999p//7v//TmDFjJEnR0dGKiIhQ+/btNWnSJEnSoUOHtG3bNg0fPvymxwDcEgyA2978+fONpBy/PD097f2OHTtmJBkfHx9z5swZh2OMGzfOSDIREREO7Xv27DGSzLPPPuvQ/re//c1IMhs2bLC3VatWzUgya9asyXPtkydPNt7e3iYpKckYY8z//d//GUnms88+y7G+a4392LFj9rb69eubNm3aZOv717/+1UgyW7dutbclJyeb6tWrm6CgIJORkWGMMWbevHlGkpkyZUq2Y2RmZhpjjFmxYoWRZF5//XWH7U888YSx2Wzmp59+srdJMm5ububAgQM51t66dWtz5coVh5p8fX3NwIEDHfrHxcWZMmXKOLTndF5SUlKy1R0WFmZq1Kjh0Hat87Rx40YjyWzcuNEYY0xaWprx8/MzDRo0MJcuXbL3W7lypZFkxo4da2/r27evkWQmTJjgcMwmTZqYkJCQbO91NUlm3Lhx2dqrVatm+vbta3+dde5CQkJMWlqavf2tt94yksznn3+e6/s8//zzOX4/5Wde82LkyJFGkjl48GCe+lerVs107tz5mtunTp2abXxXz3daWppp0KCBadeunb0tMTHReHl5mRdeeMGh77Bhw0zJkiXNhQsXjDHGDB8+3Pj4+Dh8PwK3G5ZVAHeQ2bNnKzo62uFr9erV2fp169ZNFStWzPEYgwcPdni9atUqSVJUVJRDe9YNQ1cvSahevbrDr2ivZ9GiRercubNKly4tSapdu7ZCQkJyXFpxs1atWqVmzZrZl4tIf1yNGzRokI4fP66DBw9K+mMNdIUKFTR06NBsx8i6Grlq1SoVK1ZMw4YNc9g+cuRIGWOynfc2bdqoXr16OdY1cOBAFStWzP46OjpaiYmJioiI0Llz5+xfxYoVU/PmzbVx48Zcx/nnNd5Zv01o06aNfv75Z50/fz7XfXOya9cunTlzRkOGDHFYi9y5c2fVrVs3x2UpV38f3X///fr555/z/d7XM2jQILm7u9tf/+Uvf1Hx4sXt37f5ld95zU1mZqaWLFmiJk2aKDg4+IbquVqpUqUk/XGjXpY/z/fvv/+u8+fP6/7779fu3bvt7WXKlNGjjz6qjz/+2P4boYyMDC1dulTh4eH2de6+vr66ePGioqOjnVIvcCtiWQVwB2nWrFmebsjL6YkW19p24sQJubm5qVatWg7t/v7+8vX11YkTJ/J87KsdOnRI33//vfr06aOffvrJ3v7ggw9q9uzZSkpKko+PT56Pdz0nTpxQ8+bNs7VnBZcTJ06oQYMGOnr0qOrUqaPixa/9R+iJEycUEBBgD/U5HevP8nPOf/zxR0lSu3btcux/vXOybds2jRs3TjExMUpJSXHYdv78eZUpUybX/a+WNZaclsjUrVtX33zzjUObl5dXtn98lS1b9rprgW/E1Y9HK1WqlCpXrmxfg55f+Z3X3GzevFmnTp3SiBEjbqiWnGQ9CePP9a1cuVKvv/669uzZ43AfwNXLSvr06aOlS5dq69ateuCBB7Ru3TrFx8erd+/e9j5DhgzRf/7zHz300EOqUqWKOnbsqB49eqhTp05OGwNQ1AjHALLJ7ekR19qW10erXe/JFH+2cOFCSdKIESNyDBCffPKJ+vfvn+v75+Umr1tBfs55ZmampD/WHfv7+2frn1toP3r0qNq3b6+6detqypQpCgwMlIeHh1atWqWpU6faj12Q/nwV3FlcZZ7/bNGiRXJzc1NERITTjrl//35Jsv9jdevWrerataseeOABvfvuu6pcubLc3d01f/58LV682GHfsLAwVapUSQsXLtQDDzyghQsXyt/fX6GhofY+fn5+2rNnj77++mutXr1aq1ev1vz589WnTx/7fQGAqyMcA7gp1apVU2Zmpn788UeHXw3Hx8crMTFR1apVu6HjGmO0ePFitW3bVkOGDMm2/bXXXtOiRYvs4bhs2bKSpMTERIebv3K6knetIF2tWjUdOXIkW/vhw4ft2yWpZs2a2rFjh9LT0x1+ZX/1sdatW6fk5GSHq3hXH+tG1KxZU9IfQeXPwSUvvvzyS6WmpuqLL75Q1apV7e05LcXI6z94ssZy5MiRbFezjxw5clNjvVrZsmWVmJjo0JaWlqZff/01x/4//vij2rZta3994cIF/frrr3r44YdzfZ/cvkecMa+pqan65JNP9OCDDyogICBP+1zPhQsX9NlnnykwMND+s/jJJ5/Iy8tLX3/9tTw9Pe1958+fn23/YsWK6amnntKHH36oSZMmacWKFdmW9EiSh4eHunTpoi5duigzM1NDhgzRP//5T73yyivZfoMEuCLWHAO4KVkhY9q0aQ7tWR9EkHU3fH5t27ZNx48fV//+/fXEE09k+3ryySe1ceNGnT59WtL/AuOWLVvsx7h48WKOV7NKliyZLWBljWXnzp2KiYlxOMb777+voKAg+5rgbt266dy5c5o1a1a2Y2St13z44YeVkZGRrc/UqVNls9n00EMP5fOM/E9YWJh8fHz0xhtvKD09Pdv2s2fPXnPfrKBj/vSor/Pnz+cYlq51nq7WtGlT+fn56b333nP4tf3q1at16NChG/4eyEnNmjUd5liS3n///WteOX7//fcdztGcOXN05cqV657/rDW2V4/fWfO6atUqJSYm5vnZxtdz6dIl9e7dWwkJCXr55Zft4b5YsWKy2WwO5+f48eNasWJFjsfp3bu3fv/9dz333HO6cOFCtucp//bbbw6v3dzc1KhRI0nK9uhGwFVx5Ri4g6xevdp+hevPWrVqpRo1atzQMRs3bqy+ffvq/fffV2Jiotq0aaOdO3dqwYIFCg8Pd7hqlx+LFi1SsWLFrhmsunbtqpdffllLlixRVFSUOnbsqKpVq2rAgAEaNWqUihUrpnnz5qlixYo6efKkw74hISGaM2eOXn/9ddWqVUt+fn5q166dXnzxRX388cd66KGHNGzYMJUrV04LFizQsWPH9Mknn9g/Da5Pnz766KOPFBUVpZ07d+r+++/XxYsXtW7dOg0ZMkSPPvqounTporZt2+rll1/W8ePH1bhxY61du1aff/65/vrXv9rD/I3w8fHRnDlz1Lt3b917773q2bOnfZxfffWV7rvvvhyDuyR17NjRfuUvKwB98MEH8vPzy3b19Vrn6Wru7u6aNGmS+vfvrzZt2igiIsL+KLegoCCnrql99tlnNXjwYHXr1k0dOnTQ3r179fXXX1/zEx7T0tLUvn179ejRQ0eOHNG7776r1q1bq2vXrrm+T0hIiCRp2LBhCgsLU7FixdSzZ0+nzeuiRYvk6empbt265e8ESDp16pR9ydGFCxd08OBB+yfkjRw5Us8995y9b+fOnTVlyhR16tRJTz31lM6cOaPZs2erVq1a+uGHH7Idu0mTJmrQoIGWLVum4OBg3XvvvQ7bn332WSUkJKhdu3a66667dOLECc2cOVP33HOP024qBIpcUT4qA0DhyO1RbpLM/PnzjTH/e5Tb22+/ne0YWY8EO3v2bLZt6enpZvz48aZ69erG3d3dBAYGmtGjR5vLly879LveY6iypKWlmfLly5v7778/137Vq1c3TZo0sb+OjY01zZs3Nx4eHqZq1apmypQpOT7KLS4uznTu3NmULl3aSHJ4XNnRo0fNE088YXx9fY2Xl5dp1qyZWblyZbb3TklJMS+//LJ9zP7+/uaJJ54wR48etfdJTk42I0aMMAEBAcbd3d3Url3bvP322/bHvWWRZJ5//vls75FV+3fffZfj+Ddu3GjCwsJMmTJljJeXl6lZs6bp16+f2bVrl71PTo9y++KLL0yjRo2Ml5eXCQoKMpMmTbI/ni4v5+nqR7llWbp0qWnSpInx9PQ05cqVM7169TK//PKLQ5++ffuakiVLZhvLtR7Fd7WMjAzzwgsvmAoVKpgSJUqYsLAw89NPP13zUW6bN282gwYNMmXLljWlSpUyvXr1Mr/99tt13+fKlStm6NChpmLFisZmsznUltd5vZbz588bLy8v8/jjj+ep/59lPQ5RkrHZbMbHx8fUr1/fDBw40OzYsSPHfebOnWtq165tPD09Td26dc38+fNzPd9Zj7t74403sm1bvny56dixo/Hz87P/nD333HPm119/zfdYgFuVzRgnf3A8AABFLOtDSb777rt8f2T6nW769OkaMWKEjh8/7rAuHbhTsOYYAABI+mMt+ty5c9WmTRuCMe5YrDkGAOAOd/HiRX3xxRfauHGj9u3bp88//7yoSwKKDOEYAIA73NmzZ/XUU0/J19dXL7300nVvWARuZ6w5BgAAACysOQYAAAAshGMAAADAwppjJ8jMzNTp06dVunTpPH/cKgAAAAqPMUbJyckKCAiwf6hTTgjHTnD69GkFBgYWdRkAAAC4jv/+97+66667rrmdcOwEpUuXlvTHyfbx8Snialxfenq61q5dq44dO8rd3b2oy8ENYA5dH3Po2pg/18ccOl9SUpICAwPtue1aCMdOkLWUwsfHh3DsBOnp6SpRooR8fHz4A8FFMYeujzl0bcyf62MOC871lsByQx4AAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYHG5cDx79mwFBQXJy8tLzZs3186dO3Ptv2zZMtWtW1deXl5q2LChVq1adc2+gwcPls1m07Rp05xcNQAAAFyBS4XjpUuXKioqSuPGjdPu3bvVuHFjhYWF6cyZMzn2//bbbxUREaEBAwbo+++/V3h4uMLDw7V///5sfT/77DNt375dAQEBBT0MAAAA3KJcKhxPmTJFAwcOVP/+/VWvXj299957KlGihObNm5dj/+nTp6tTp04aNWqUgoOD9dprr+nee+/VrFmzHPqdOnVKQ4cO1aJFi+Tu7l4YQwEAAMAtqHhRF5BXaWlpio2N1ejRo+1tbm5uCg0NVUxMTI77xMTEKCoqyqEtLCxMK1assL/OzMxU7969NWrUKNWvXz9PtaSmpio1NdX+OikpSZKUnp6u9PT0vA4J15B1DjmXros5dH3MoWtj/lwfc+h8eT2XLhOOz507p4yMDFWqVMmhvVKlSjp8+HCO+8TFxeXYPy4uzv560qRJKl68uIYNG5bnWiZOnKjx48dna1+7dq1KlCiR5+Mgd9HR0UVdAm4Sc+j6mEPXxvy5PubQeVJSUvLUz2XCcUGIjY3V9OnTtXv3btlstjzvN3r0aIcr0klJSQoMDFTHjh3l4+NTEKXeUdLT0xUdHa0OHTqwzMVFMYeujzl0bcyf62MOnS/rN/3X4zLhuEKFCipWrJji4+Md2uPj4+Xv75/jPv7+/rn237p1q86cOaOqVavat2dkZGjkyJGaNm2ajh8/nuNxPT095enpma3d3d2db2An4ny6PubQ9TGHro35c33MofPk9Ty6zA15Hh4eCgkJ0fr16+1tmZmZWr9+vVq2bJnjPi1btnToL/3x64ms/r1799YPP/ygPXv22L8CAgI0atQoff311wU3GAAAANySXObKsSRFRUWpb9++atq0qZo1a6Zp06bp4sWL6t+/vySpT58+qlKliiZOnChJGj58uNq0aaN33nlHnTt31pIlS7Rr1y69//77kqTy5curfPnyDu/h7u4uf39/1alTp3AHBwAAgCLnUuH4ySef1NmzZzV27FjFxcXpnnvu0Zo1a+w33Z08eVJubv+7GN6qVSstXrxYY8aM0UsvvaTatWtrxYoVatCgQVENAQAAALcwlwrHkhQZGanIyMgct23atClbW/fu3dW9e/c8H/9a64wBAABw+3OZNccAAABAQSMcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgcblwPHv2bAUFBcnLy0vNmzfXzp07c+2/bNky1a1bV15eXmrYsKFWrVpl35aenq4XXnhBDRs2VMmSJRUQEKA+ffro9OnTBT0MAAAA3IJcKhwvXbpUUVFRGjdunHbv3q3GjRsrLCxMZ86cybH/t99+q4iICA0YMEDff/+9wsPDFR4erv3790uSUlJStHv3br3yyivavXu3Pv30Ux05ckRdu3YtzGEBAADgFuFS4XjKlCkaOHCg+vfvr3r16um9995TiRIlNG/evBz7T58+XZ06ddKoUaMUHBys1157Tffee69mzZolSSpTpoyio6PVo0cP1alTRy1atNCsWbMUGxurkydPFubQAAAAcAsoXtQF5FVaWppiY2M1evRoe5ubm5tCQ0MVExOT4z4xMTGKiopyaAsLC9OKFSuu+T7nz5+XzWaTr6/vNfukpqYqNTXV/jopKUnSH8s00tPT8zAa5CbrHHIuXRdz6PqYQ9fG/Lk+5tD58nouXSYcnzt3ThkZGapUqZJDe6VKlXT48OEc94mLi8uxf1xcXI79L1++rBdeeEERERHy8fG5Zi0TJ07U+PHjs7WvXbtWJUqUuN5QkEfR0dFFXQJuEnPo+phD18b8uT7m0HlSUlLy1M9lwnFBS09PV48ePWSM0Zw5c3LtO3r0aIcr0klJSQoMDFTHjh1zDdXIm/T0dEVHR6tDhw5yd3cv6nJwA5hD18ccujbmz/Uxh86X9Zv+63GZcFyhQgUVK1ZM8fHxDu3x8fHy9/fPcR9/f/889c8KxidOnNCGDRuuG3A9PT3l6emZrd3d3Z1vYCfifLo+5tD1MYeujflzfcyh8+T1PLrMDXkeHh4KCQnR+vXr7W2ZmZlav369WrZsmeM+LVu2dOgv/fHriT/3zwrGP/74o9atW6fy5csXzAAAAABwy3OZK8eSFBUVpb59+6pp06Zq1qyZpk2bposXL6p///6SpD59+qhKlSqaOHGiJGn48OFq06aN3nnnHXXu3FlLlizRrl279P7770v6Ixg/8cQT2r17t1auXKmMjAz7euRy5crJw8OjaAYKAACAIuFS4fjJJ5/U2bNnNXbsWMXFxemee+7RmjVr7DfdnTx5Um5u/7sY3qpVKy1evFhjxozRSy+9pNq1a2vFihVq0KCBJOnUqVP64osvJEn33HOPw3tt3LhRDz74YKGMCwAAALcGlwrHkhQZGanIyMgct23atClbW/fu3dW9e/cc+wcFBckY48zyAAAA4MJcZs0xAAAAUNAIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFiK53eHixcv6s0339T69et15swZZWZmOmz/+eefnVYcAAAAUJjyHY6fffZZbd68Wb1791blypVls9kKoi4AAACg0OU7HK9evVpfffWV7rvvvoKoBwAAACgy+V5zXLZsWZUrV64gagEAAACKVL7D8WuvvaaxY8cqJSWlIOoBAAAAiky+l1W88847Onr0qCpVqqSgoCC5u7s7bN+9e7fTigMAAAAKU77DcXh4eAGUAQAAABS9fIfjcePGFUQdAAAAQJHLdzjOEhsbq0OHDkmS6tevryZNmjitKAAAAKAo5DscnzlzRj179tSmTZvk6+srSUpMTFTbtm21ZMkSVaxY0dk1AgAAAIUi30+rGDp0qJKTk3XgwAElJCQoISFB+/fvV1JSkoYNG1YQNQIAAACFIt9XjtesWaN169YpODjY3lavXj3Nnj1bHTt2dGpxAAAAQGHK95XjzMzMbI9vkyR3d3dlZmY6pSgAAACgKOQ7HLdr107Dhw/X6dOn7W2nTp3SiBEj1L59e6cWBwAAABSmfIfjWbNmKSkpSUFBQapZs6Zq1qyp6tWrKykpSTNnziyIGgEAAIBCke81x4GBgdq9e7fWrVunw4cPS5KCg4MVGhrq9OIAAACAwnRDzzm22Wzq0KGDOnTo4Ox6AAAAgCKTp3A8Y8YMDRo0SF5eXpoxY0aufXmcGwAAAFxVnsLx1KlT1atXL3l5eWnq1KnX7Gez2QjHAAAAcFl5CsfHjh3L8f8BAACA20m+n1YxYcIEpaSkZGu/dOmSJkyY4JSiAAAAgKKQ73A8fvx4XbhwIVt7SkqKxo8f75SiAAAAgKKQ73BsjJHNZsvWvnfvXpUrV84pRQEAAABFIc+PcitbtqxsNptsNpvuvvtuh4CckZGhCxcuaPDgwQVSJAAAAFAY8hyOp02bJmOMnnnmGY0fP15lypSxb/Pw8FBQUJBatmxZIEUCAAAAhSHP4bhv376SpOrVq6tVq1Zyd3cvsKIAAACAopDvT8hr06aN/f8vX76stLQ0h+0+Pj43XxUAAABQBPJ9Q15KSooiIyPl5+enkiVLqmzZsg5fAAAAgKvKdzgeNWqUNmzYoDlz5sjT01P/+te/NH78eAUEBOijjz4qiBoBAACAQpHvZRVffvmlPvroIz344IPq37+/7r//ftWqVUvVqlXTokWL1KtXr4KoEwAAAChw+b5ynJCQoBo1akj6Y31xQkKCJKl169basmWLc6sDAAAAClG+w3GNGjV07NgxSVLdunX1n//8R9IfV5R9fX2dWhwAAABQmPIdjvv376+9e/dKkl588UXNnj1bXl5eGjFihEaNGuX0AgEAAIDCku81xyNGjLD/f2hoqA4fPqzY2FjVqlVLjRo1cmpxAAAAQGHKdzi+WrVq1VStWjVn1AIAAAAUqTyF4xkzZuT5gMOGDbvhYgAAAICilKdwPHXq1DwdzGazEY4BAADgsvIUjrOeTgEAAADczvL9tIosaWlpOnLkiK5cueLMegAAAIAik+9wnJKSogEDBqhEiRKqX7++Tp48KUkaOnSo3nzzTacXCAAAABSWfIfj0aNHa+/evdq0aZO8vLzs7aGhoVq6dKlTiwMAAAAKU74f5bZixQotXbpULVq0kM1ms7fXr19fR48edWpxAAAAQGHK95Xjs2fPys/PL1v7xYsXHcIyAAAA4GryHY6bNm2qr776yv46KxD/61//UsuWLZ1XGQAAAFDI8r2s4o033tBDDz2kgwcP6sqVK5o+fboOHjyob7/9Vps3by6IGgEAAIBCke8rx61bt9bevXt15coVNWzYUGvXrpWfn59iYmIUEhJSEDUCAAAAhSJf4Tg9PV3PPPOMbDabPvjgA+3cuVMHDx7UwoUL1bBhw4Kq0cHs2bMVFBQkLy8vNW/eXDt37sy1/7Jly1S3bl15eXmpYcOGWrVqlcN2Y4zGjh2rypUry9vbW6Ghofrxxx8LcggAAAC4ReUrHLu7u+uTTz4pqFqua+nSpYqKitK4ceO0e/duNW7cWGFhYTpz5kyO/b/99ltFRERowIAB+v777xUeHq7w8HDt37/f3uett97SjBkz9N5772nHjh0qWbKkwsLCdPny5cIaFgAAAG4R+V5WER4erhUrVhRAKdc3ZcoUDRw4UP3791e9evX03nvvqUSJEpo3b16O/adPn65OnTpp1KhRCg4O1muvvaZ7771Xs2bNkvTHVeNp06ZpzJgxevTRR9WoUSN99NFHOn36dJGNEQAAAEUn3zfk1a5dWxMmTNC2bdsUEhKikiVLOmwfNmyY04r7s7S0NMXGxmr06NH2Njc3N4WGhiomJibHfWJiYhQVFeXQFhYWZg++x44dU1xcnEJDQ+3by5Qpo+bNmysmJkY9e/bM8bipqalKTU21v05KSpL0x7KT9PT0Gxof/ifrHHIuXRdz6PqYQ9fG/Lk+5tD58nou8x2O586dK19fX8XGxio2NtZhm81mK7BwfO7cOWVkZKhSpUoO7ZUqVdLhw4dz3CcuLi7H/nFxcfbtWW3X6pOTiRMnavz48dna165dqxIlSlx/MMiT6Ojooi4BN4k5dH3MoWtj/lwfc+g8KSkpeeqXr3BsjNGmTZvk5+cnb2/vGyrsdjB69GiHK9JJSUkKDAxUx44d5ePjU4SV3R7S09MVHR2tDh06yN3dvajLwQ1gDl0fc+jamD/Xxxw6X9Zv+q8n3+G4du3aOnDggGrXrn1Dhd2oChUqqFixYoqPj3doj4+Pl7+/f477+Pv759o/67/x8fGqXLmyQ5977rnnmrV4enrK09MzW7u7uzvfwE7E+XR9zKHrYw5dG/Pn+phD58nreczXDXlubm6qXbu2fvvttxsq6mZ4eHgoJCRE69evt7dlZmZq/fr11/xkvpYtWzr0l/749URW/+rVq8vf39+hT1JSknbs2MGn/QEAANyB8v20ijfffFOjRo1yeBxaYYmKitIHH3ygBQsW6NChQ/rLX/6iixcvqn///pKkPn36ONywN3z4cK1Zs0bvvPOODh8+rFdffVW7du1SZGSkpD/WSP/1r3/V66+/ri+++EL79u1Tnz59FBAQoPDw8EIfHwAAAIpWvm/I69Onj1JSUtS4cWN5eHhkW3uckJDgtOKu9uSTT+rs2bMaO3as4uLidM8992jNmjX2G+pOnjwpN7f/5f1WrVpp8eLFGjNmjF566SXVrl1bK1asUIMGDex9/v73v+vixYsaNGiQEhMT1bp1a61Zs0ZeXl4FNg4AAADcmvIdjqdNm1YAZeRdZGSk/crv1TZt2pStrXv37urevfs1j2ez2TRhwgRNmDDBWSUCAADAReU7HPft27cg6gAAAACKXL7DsSRlZGRoxYoVOnTokCSpfv366tq1q4oVK+bU4gAAAIDClO9w/NNPP+nhhx/WqVOnVKdOHUl/fChGYGCgvvrqK9WsWdPpRQIAAACFId9Pqxg2bJhq1qyp//73v9q9e7d2796tkydPqnr16gX26XgAAABAYcj3lePNmzdr+/btKleunL2tfPnyevPNN3Xfffc5tTgAAACgMOX7yrGnp6eSk5OztV+4cEEeHh5OKQoAAAAoCvkOx4888ogGDRqkHTt2yBgjY4y2b9+uwYMHq2vXrgVRIwAAAFAo8h2OZ8yYoZo1a6ply5by8vKSl5eX7rvvPtWqVUvTp08viBoBAACAQpHvNce+vr76/PPP9dNPP9kf5RYcHKxatWo5vTgAAACgMN3Qc44lqVatWgRiAAAA3FbyvayiW7dumjRpUrb2t956K9ePaQYAAABudfkOx1u2bNHDDz+crf2hhx7Sli1bnFIUAAAAUBTyHY6v9cg2d3d3JSUlOaUoAAAAoCjkOxw3bNhQS5cuzda+ZMkS1atXzylFAQAAAEUh3zfkvfLKK3r88cd19OhRtWvXTpK0fv16ffzxx1q2bJnTCwQAAAAKS77DcZcuXbRixQq98cYbWr58uby9vdWoUSOtW7dObdq0KYgaAQAAgEJxQ49y69y5szp37uzsWgAAAIAidcPPOY6NjbV/CEj9+vXVpEkTpxUFAAAAFIV8h+MzZ86oZ8+e2rRpk3x9fSVJiYmJatu2rZYsWaKKFSs6u0YAAACgUOT7aRVDhw5VcnKyDhw4oISEBCUkJGj//v1KSkrSsGHDCqJGAAAAoFDk+8rxmjVrtG7dOgUHB9vb6tWrp9mzZ6tjx45OLQ4AAAAoTPm+cpyZmSl3d/ds7e7u7srMzHRKUQAAAEBRyHc4bteunYYPH67Tp0/b206dOqURI0aoffv2Ti0OAAAAKEz5DsezZs1SUlKSgoKCVLNmTdWsWVPVq1dXUlKSZs6cWRA1AgAAAIUi32uOAwMDtXv3bq1bt06HDx+WJAUHBys0NNTpxQEAAACFKd/h+KOPPtKTTz6pDh06qEOHDvb2tLQ0LVmyRH369HFqgQAAAEBhyfeyiv79++v8+fPZ2pOTk9W/f3+nFAUAAAAUhXyHY2OMbDZbtvZffvlFZcqUcUpRAAAAQFHI87KKJk2ayGazyWazqX379ipe/H+7ZmRk6NixY+rUqVOBFAkAAAAUhjyH4/DwcEnSnj17FBYWplKlStm3eXh4KCgoSN26dXN6gQAAAEBhyXM4HjdunCQpKChITz75pLy8vAqsKAAAAKAo5PtpFX379i2IOgAAAIAil+9w7ObmluMNeVkyMjJuqiAAAACgqOQ7HH/66acO4Tg9PV3ff/+9FixYoPHjxzu1OAAAAKAw5TscZ92Y92dPPPGE6tevr6VLl2rAgAHOqAsAAAAodPl+zvG1tGjRQuvXr3fW4QAAAIBC55RwfOnSJc2YMUNVqlRxxuEAAACAIpHvZRVly5Z1WHNsjFFycrK8vb21aNEipxYHAAAAFKZ8h+Np06Y5vHZzc1PFihXVvHlznTp1yll1AQAAAIXupp9znJycrI8//ljjxo3Trl27eJQbAAAAXNYNrznesmWL+vbtq8qVK2vy5Mlq27attm/f7szaAAAAgEKVryvHcXFx+vDDDzV37lwlJSWpR48eSk1N1YoVK1SvXr2CqhEAAAAoFHm+ctylSxfVqVNHP/zwg6ZNm6bTp09r5syZBVkbAAAAUKjyfOV49erVGjZsmP7yl7+odu3aBVkTAAAAUCTyfOX4m2++UXJyskJCQtS8eXPNmjVL586dK8jaAAAAgEKV53DcokULffDBB/r111/13HPPacmSJQoICFBmZqaio6OVnJxckHUCAAAABS7fT6soWbKknnnmGX3zzTfat2+fRo4cqTfffFN+fn7q2rVrQdQIAAAAFIqb+vjoOnXq6K233tIvv/yijz/+2Fk1AQAAAEXipsJxlmLFiik8PFxffPGFMw4HAAAAFAmnhGMAAADgdkA4BgAAACyEYwAAAMBCOAYAAAAshGMAAADAQjgGAAAALIRjAAAAwEI4BgAAACyEYwAAAMBCOAYAAAAsLhOOExIS1KtXL/n4+MjX11cDBgzQhQsXct3n8uXLev7551W+fHmVKlVK3bp1U3x8vH373r17FRERocDAQHl7eys4OFjTp08v6KEAAADgFuUy4bhXr146cOCAoqOjtXLlSm3ZskWDBg3KdZ8RI0boyy+/1LJly7R582adPn1ajz/+uH17bGys/Pz8tHDhQh04cEAvv/yyRo8erVmzZhX0cAAAAHALKl7UBeTFoUOHtGbNGn333Xdq2rSpJGnmzJl6+OGHNXnyZAUEBGTb5/z585o7d64WL16sdu3aSZLmz5+v4OBgbd++XS1atNAzzzzjsE+NGjUUExOjTz/9VJGRkQU/MAAAANxSXCIcx8TEyNfX1x6MJSk0NFRubm7asWOHHnvssWz7xMbGKj09XaGhofa2unXrqmrVqoqJiVGLFi1yfK/z58+rXLlyudaTmpqq1NRU++ukpCRJUnp6utLT0/M1NmSXdQ45l66LOXR9zKFrY/5cH3PofHk9ly4RjuPi4uTn5+fQVrx4cZUrV05xcXHX3MfDw0O+vr4O7ZUqVbrmPt9++62WLl2qr776Ktd6Jk6cqPHjx2drX7t2rUqUKJHrvsi76Ojooi4BN4k5dH3MoWtj/lwfc+g8KSkpeepXpOH4xRdf1KRJk3Ltc+jQoUKpZf/+/Xr00Uc1btw4dezYMde+o0ePVlRUlP11UlKSAgMD1bFjR/n4+BR0qbe99PR0RUdHq0OHDnJ3dy/qcnADmEPXxxy6NubP9TGHzpf1m/7rKdJwPHLkSPXr1y/XPjVq1JC/v7/OnDnj0H7lyhUlJCTI398/x/38/f2VlpamxMREh6vH8fHx2fY5ePCg2rdvr0GDBmnMmDHXrdvT01Oenp7Z2t3d3fkGdiLOp+tjDl0fc+jamD/Xxxw6T17PY5GG44oVK6pixYrX7deyZUslJiYqNjZWISEhkqQNGzYoMzNTzZs3z3GfkJAQubu7a/369erWrZsk6ciRIzp58qRatmxp73fgwAG1a9dOffv21T/+8Q8njAoAAACuyiUe5RYcHKxOnTpp4MCB2rlzp7Zt26bIyEj17NnT/qSKU6dOqW7dutq5c6ckqUyZMhowYICioqK0ceNGxcbGqn///mrZsqX9Zrz9+/erbdu26tixo6KiohQXF6e4uDidPXu2yMYKAACAouMSN+RJ0qJFixQZGan27dvLzc1N3bp104wZM+zb09PTdeTIEYfF1lOnTrX3TU1NVVhYmN5991379uXLl+vs2bNauHChFi5caG+vVq2ajh8/XijjAgAAwK3DZcJxuXLltHjx4mtuDwoKkjHGoc3Ly0uzZ8/W7Nmzc9zn1Vdf1auvvurMMgEAAODCXGJZBQAAAFAYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFhcJhwnJCSoV69e8vHxka+vrwYMGKALFy7kus/ly5f1/PPPq3z58ipVqpS6deum+Pj4HPv+9ttvuuuuu2Sz2ZSYmFgAIwAAAMCtzmXCca9evXTgwAFFR0dr5cqV2rJliwYNGpTrPiNGjNCXX36pZcuWafPmzTp9+rQef/zxHPsOGDBAjRo1KojSAQAA4CJcIhwfOnRIa9as0b/+9S81b95crVu31syZM7VkyRKdPn06x33Onz+vuXPnasqUKWrXrp1CQkI0f/58ffvtt9q+fbtD3zlz5igxMVF/+9vfCmM4AAAAuEUVL+oC8iImJka+vr5q2rSpvS00NFRubm7asWOHHnvssWz7xMbGKj09XaGhofa2unXrqmrVqoqJiVGLFi0kSQcPHtSECRO0Y8cO/fzzz3mqJzU1VampqfbXSUlJkqT09HSlp6ff0BjxP1nnkHPpuphD18ccujbmz/Uxh86X13PpEuE4Li5Ofn5+Dm3FixdXuXLlFBcXd819PDw85Ovr69BeqVIl+z6pqamKiIjQ22+/rapVq+Y5HE+cOFHjx4/P1r527VqVKFEiT8fA9UVHRxd1CbhJzKHrYw5dG/Pn+phD50lJSclTvyINxy+++KImTZqUa59Dhw4V2PuPHj1awcHBevrpp/O9X1RUlP11UlKSAgMD1bFjR/n4+Di7zDtOenq6oqOj1aFDB7m7uxd1ObgBzKHrYw5dG/Pn+phD58v6Tf/1FGk4HjlypPr165drnxo1asjf319nzpxxaL9y5YoSEhLk7++f437+/v5KS0tTYmKiw9Xj+Ph4+z4bNmzQvn37tHz5ckmSMUaSVKFCBb388ss5Xh2WJE9PT3l6emZrd3d35xvYiTifro85dH3MoWtj/lwfc+g8eT2PRRqOK1asqIoVK163X8uWLZWYmKjY2FiFhIRI+iPYZmZmqnnz5jnuExISInd3d61fv17dunWTJB05ckQnT55Uy5YtJUmffPKJLl26ZN/nu+++0zPPPKOtW7eqZs2aNzs8AAAAuBiXWHMcHBysTp06aeDAgXrvvfeUnp6uyMhI9ezZUwEBAZKkU6dOqX379vroo4/UrFkzlSlTRgMGDFBUVJTKlSsnHx8fDR06VC1btrTfjHd1AD537pz9/a5eqwwAAIDbn0uEY0latGiRIiMj1b59e7m5ualbt26aMWOGfXt6erqOHDnisNh66tSp9r6pqakKCwvTu+++WxTlAwAAwAW4TDguV66cFi9efM3tQUFB9jXDWby8vDR79mzNnj07T+/x4IMPZjsGAAAA7hwu8SEgAAAAQGEgHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgIRwDAAAAFsIxAAAAYCEcAwAAABbCMQAAAGAhHAMAAAAWwjEAAABgKV7UBdwOjDGSpKSkpCKu5PaQnp6ulJQUJSUlyd3dvajLwQ1gDl0fc+jamD/Xxxw6X1ZOy8pt10I4doLk5GRJUmBgYBFXAgAAgNwkJyerTJky19xuM9eLz7iuzMxMnT59WqVLl5bNZivqclxeUlKSAgMD9d///lc+Pj5FXQ5uAHPo+phD18b8uT7m0PmMMUpOTlZAQIDc3K69spgrx07g5uamu+66q6jLuO34+PjwB4KLYw5dH3Po2pg/18ccOlduV4yzcEMeAAAAYCEcAwAAABbCMW45np6eGjdunDw9PYu6FNwg5tD1MYeujflzfcxh0eGGPAAAAMDClWMAAADAQjgGAAAALIRjAAAAwEI4BgAAACyEYxS6hIQE9erVSz4+PvL19dWAAQN04cKFXPe5fPmynn/+eZUvX16lSpVSt27dFB8fn2Pf3377TXfddZdsNpsSExMLYAQoiDncu3evIiIiFBgYKG9vbwUHB2v69OkFPZQ7xuzZsxUUFCQvLy81b95cO3fuzLX/smXLVLduXXl5ealhw4ZatWqVw3ZjjMaOHavKlSvL29tboaGh+vHHHwtyCHc8Z85henq6XnjhBTVs2FAlS5ZUQECA+vTpo9OnTxf0MO5ozv45/LPBgwfLZrNp2rRpTq76DmSAQtapUyfTuHFjs337drN161ZTq1YtExERkes+gwcPNoGBgWb9+vVm165dpkWLFqZVq1Y59n300UfNQw89ZCSZ33//vQBGgIKYw7lz55phw4aZTZs2maNHj5p///vfxtvb28ycObOgh3PbW7JkifHw8DDz5s0zBw4cMAMHDjS+vr4mPj4+x/7btm0zxYoVM2+99ZY5ePCgGTNmjHF3dzf79u2z93nzzTdNmTJlzIoVK8zevXtN165dTfXq1c2lS5cKa1h3FGfPYWJiogkNDTVLly41hw8fNjExMaZZs2YmJCSkMId1RymIn8Msn376qWncuLEJCAgwU6dOLeCR3P4IxyhUBw8eNJLMd999Z29bvXq1sdls5tSpUznuk5iYaNzd3c2yZcvsbYcOHTKSTExMjEPfd99917Rp08asX7+ecFxACnoO/2zIkCGmbdu2ziv+DtWsWTPz/PPP219nZGSYgIAAM3HixBz79+jRw3Tu3NmhrXnz5ua5554zxhiTmZlp/P39zdtvv23fnpiYaDw9Pc3HH39cACOAs+cwJzt37jSSzIkTJ5xTNBwU1Bz+8ssvpkqVKmb//v2mWrVqhGMnYFkFClVMTIx8fX3VtGlTe1toaKjc3Ny0Y8eOHPeJjY1Venq6QkND7W1169ZV1apVFRMTY287ePCgJkyYoI8++khubnxrF5SCnMOrnT9/XuXKlXNe8XegtLQ0xcbGOpx7Nzc3hYaGXvPcx8TEOPSXpLCwMHv/Y8eOKS4uzqFPmTJl1Lx581znEzemIOYwJ+fPn5fNZpOvr69T6sb/FNQcZmZmqnfv3ho1apTq169fMMXfgUgQKFRxcXHy8/NzaCtevLjKlSunuLi4a+7j4eGR7Q/sSpUq2fdJTU1VRESE3n77bVWtWrVAascfCmoOr/btt99q6dKlGjRokFPqvlOdO3dOGRkZqlSpkkN7buc+Li4u1/5Z/83PMXHjCmIOr3b58mW98MILioiIkI+Pj3MKh11BzeGkSZNUvHhxDRs2zPlF38EIx3CKF198UTabLdevw4cPF9j7jx49WsHBwXr66acL7D1ud0U9h3+2f/9+Pfrooxo3bpw6duxYKO8J3KnS09PVo0cPGWM0Z86coi4HeRQbG6vp06frww8/lM1mK+pybivFi7oA3B5Gjhypfv365dqnRo0a8vf315kzZxzar1y5ooSEBPn7++e4n7+/v9LS0pSYmOhw5TE+Pt6+z4YNG7Rv3z4tX75c0h930ktShQoV9PLLL2v8+PE3OLI7R1HPYZaDBw+qffv2GjRokMaMGXNDY8H/VKhQQcWKFcv2dJeczn0Wf3//XPtn/Tc+Pl6VK1d26HPPPfc4sXpIBTOHWbKC8YkTJ7RhwwauGheQgpjDrVu36syZMw6/Lc3IyNDIkSM1bdo0HT9+3LmDuJMU9aJn3FmybubatWuXve3rr7/O081cy5cvt7cdPnzY4Waun376yezbt8/+NW/ePCPJfPvtt9e8Exg3pqDm0Bhj9u/fb/z8/MyoUaMKbgB3oGbNmpnIyEj764yMDFOlSpVcbwR65JFHHNpatmyZ7Ya8yZMn27efP3+eG/IKkLPn0Bhj0tLSTHh4uKlfv745c+ZMwRQOO2fP4blz5xz+3tu3b58JCAgwL7zwgjl8+HDBDeQOQDhGoevUqZNp0qSJ2bFjh/nmm29M7dq1HR4D9ssvv5g6deqYHTt22NsGDx5sqlatajZs2GB27dplWrZsaVq2bHnN99i4cSNPqyhABTGH+/btMxUrVjRPP/20+fXXX+1f/KV985YsWWI8PT3Nhx9+aA4ePGgGDRpkfH19TVxcnDHGmN69e5sXX3zR3n/btm2mePHiZvLkyebQoUNm3LhxOT7KzdfX13z++efmhx9+MI8++iiPcitAzp7DtLQ007VrV3PXXXeZPXv2OPzMpaamFskYb3cF8XN4NZ5W4RyEYxS63377zURERJhSpUoZHx8f079/f5OcnGzffuzYMSPJbNy40d526dIlM2TIEFO2bFlTokQJ89hjj5lff/31mu9BOC5YBTGH48aNM5KyfVWrVq0QR3b7mjlzpqlatarx8PAwzZo1M9u3b7dva9Omjenbt69D///85z/m7rvvNh4eHqZ+/frmq6++ctiemZlpXnnlFVOpUiXj6elp2rdvb44cOVIYQ7ljOXMOs35Gc/r6888tnMvZP4dXIxw7h80Ya3EmAAAAcIfjaRUAAACAhXAMAAAAWAjHAAAAgIVwDAAAAFgIxwAAAICFcAwAAABYCMcAAACAhXAMAAAAWAjHAADNnTtXHTt2zLVPv379FB4eXjgFSerZs6feeeedQns/AJAIxwBwyyjs8Jnl8uXLeuWVVzRu3LhCf+/cjBkzRv/4xz90/vz5oi4FwB2EcAwAd7jly5fLx8dH9913X1GX4qBBgwaqWbOmFi5cWNSlALiDEI4BwEVMmTJFDRs2VMmSJRUYGKghQ4bowoULDn0++OADBQYGqkSJEnrsscc0ZcoU+fr65nrcJUuWqEuXLg5tGRkZioqKkq+vr8qXL6+///3vMsY49FmzZo1at25t7/PII4/o6NGj9u3t2rVTZGSkwz5nz56Vh4eH1q9fL0l69913Vbt2bXl5ealSpUp64oknHPp36dJFS5YsydP5AQBnIBwDgItwc3PTjBkzdODAAS1YsEAbNmzQ3//+d/v2bdu2afDgwRo+fLj27NmjDh066B//+Md1j/vNN9+oadOmDm3vvPOOPvzwQ82bN0/ffPONEhIS9Nlnnzn0uXjxoqKiorRr1y6tX79ebm5ueuyxx5SZmSlJevbZZ7V48WKlpqba91m4cKGqVKmidu3aadeuXRo2bJgmTJigI0eOaM2aNXrggQcc3qNZs2bauXOnwzEAoCDZzNWXAgAARaJfv35KTEzUihUr8tR/+fLlGjx4sM6dOyfpjxvYLly4oJUrV9r7PP3001q5cqUSExNzPEZiYqLKli2rLVu26P7777e3BwQEaMSIERo1apQk6cqVK6pevbpCQkKuWd+5c+dUsWJF7du3Tw0aNNDly5cVEBCg9957Tz169JAkNW7cWI8//rjGjRunTz/9VP3799cvv/yi0qVL53jMH374QY0bN9bx48dVrVq1PJ0XALgZXDkGABexbt06tW/fXlWqVFHp0qXVu3dv/fbbb0pJSZEkHTlyRM2aNXPY5+rXV7t06ZIkycvLy952/vx5/frrr2revLm9rXjx4tmuLv/444+KiIhQjRo15OPjo6CgIEnSyZMn7cfs3bu35s2bJ0navXu39u/fr379+kmSOnTooGrVqqlGjRrq3bu3Fi1aZB9LFm9vb0nK1g4ABYVwDAAu4Pjx43rkkUfUqFEjffLJJ4qNjdXs2bMlSWlpaTd83PLly8tms+n333/P975dunRRQkKCPvjgA+3YsUM7duzIVs+zzz6r6Oho/fLLL5o/f77atWtnvwJcunRp7d69Wx9//LEqV66ssWPHqnHjxg5XuRMSEiRJFStWvOExAkB+EI4BwAXExsYqMzNT77zzjlq0aKG7775bp0+fduhTp04dfffddw5tV7++moeHh+rVq6eDBw/a28qUKaPKlSvbw670x7KK2NhY++vffvtNR44c0ZgxY9S+fXsFBwfnGLAbNmyopk2b6oMPPtDixYv1zDPPOGwvXry4QkND9dZbb+mHH37Q8ePHtWHDBvv2/fv366677lKFChVyHQcAOEvxoi4AAPA/58+f1549exzaypcvr1q1aik9PV0zZ85Uly5dtG3bNr333nsO/YYOHaoHHnhAU6ZMUZcuXbRhwwatXr1aNpst1/cMCwvTN998o7/+9a/2tuHDh+vNN99U7dq1VbduXU2ZMsXhim7ZsmVVvnx5vf/++6pcubJOnjypF198McfjP/vss4qMjFTJkiX12GOP2dtXrlypn3/+WQ888IDKli2rVatWKTMzU3Xq1LH32bp163U/nAQAnMoAAG4Jffv2NZKyfQ0YMMAYY8yUKVNM5cqVjbe3twkLCzMfffSRkWR+//13+zHef/99U6VKFePt7W3Cw8PN66+/bvz9/XN93wMHDhhvb2+TmJhob0tPTzfDhw83Pj4+xtfX10RFRZk+ffqYRx991N4nOjraBAcHG09PT9OoUSOzadMmI8l89tlnDsdPTk42JUqUMEOGDHFo37p1q2nTpo0pW7as8fb2No0aNTJLly61b7906ZIpU6aMiYmJyeeZBIAbx9MqAOA2NnDgQB0+fFhbt27NtV/37t117733avTo0U6v4fjx46pZs6a+++473XvvvXneb86cOfrss8+0du1ap9cEANfCmmMAuI1MnjxZe/fu1U8//aSZM2dqwYIF6tu373X3e/vtt1WqVCmn1pKenq64uDiNGTNGLVq0yFcwliR3d3fNnDnTqTUBwPVw5RgAbiM9evTQpk2blJycrBo1amjo0KEaPHhwkdSyadMmtW3bVnfffbeWL1+uhg0bFkkdAJAfhGMAAADAwrIKAAAAwEI4BgAAACyEYwAAAMBCOAYAAAAshGMAAADAQjgGAAAALIRjAAAAwEI4BgAAACz/H39bmuqRfFwTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After calculating basic metrics\n",
    "print(\"\\n=== Error Autocorrelation Analysis ===\")\n",
    "\n",
    "# Calculate error series\n",
    "errors = true_prices - predictions\n",
    "error_series = pd.Series(errors, index=pd.to_datetime(test_data['date']))\n",
    "\n",
    "# Calculate autocorrelations for lags 1-7\n",
    "lags = range(1, 8)  # 1 to 7 days\n",
    "autocorrs = []\n",
    "\n",
    "for lag in lags:\n",
    "    autocorr = error_series.autocorr(lag=lag)\n",
    "    autocorrs.append({\n",
    "        'lag': lag,\n",
    "        'autocorrelation': autocorr\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(\"\\nError Autocorrelations:\")\n",
    "for result in autocorrs:\n",
    "    print(f\"Lag {result['lag']} day(s): {result['autocorrelation']:.4f}\")\n",
    "\n",
    "# Simple plot of autocorrelations\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([r['lag'] for r in autocorrs], [r['autocorrelation'] for r in autocorrs], 'bo-')\n",
    "plt.title('Error Autocorrelation up to 7 Days')\n",
    "plt.xlabel('Lag (days)')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
