{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Total listings in sample: 500\n",
      "Total records in sample: 332673\n",
      "Date range: 2023-06-07 00:00:00 to 2025-09-12 00:00:00\n",
      "\n",
      "Analyzing price stability...\n",
      "\n",
      "Price Stability Analysis:\n",
      "constant_price_listings: 262.00\n",
      "avg_unique_prices: 4.80\n",
      "max_unique_prices: 105.00\n",
      "avg_price_std: 28.86\n",
      "price_range: 9989.00\n",
      "\n",
      "Training ARIMA model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 177\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax daily listings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 125\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining ARIMA model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m model, results_df, test_data \u001b[38;5;241m=\u001b[39m train_simple_arima(\n\u001b[0;32m    126\u001b[0m     df,\n\u001b[0;32m    127\u001b[0m     history_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m365\u001b[39m,\n\u001b[0;32m    128\u001b[0m     forecast_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m\n\u001b[0;32m    129\u001b[0m )\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Evaluate predictions\u001b[39;00m\n\u001b[0;32m    132\u001b[0m metrics, results_df, monthly_analysis \u001b[38;5;241m=\u001b[39m evaluate_predictions(\n\u001b[0;32m    133\u001b[0m     results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    134\u001b[0m     results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    135\u001b[0m     results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    136\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_and_prepare_data(calendar_path, listings_path, n_listings=500):\n",
    "    \"\"\"Load and prepare the data with basic cleaning and sampling.\"\"\"\n",
    "    # Load listings first to get the sample\n",
    "    listings_df = pd.read_csv(listings_path)\n",
    "    sampled_listings = listings_df['id'].sample(n=n_listings, random_state=42)\n",
    "    \n",
    "    # Clean and prepare listings data\n",
    "    listings_cleaned = listings_df[listings_df['id'].isin(sampled_listings)][\n",
    "        ['id', 'neighbourhood_cleansed']\n",
    "    ]\n",
    "    listings_cleaned = listings_cleaned.rename(columns={'id': 'listing_id'})\n",
    "    \n",
    "    # Load and filter calendar data\n",
    "    calendar_df = pd.read_csv(calendar_path)\n",
    "    calendar_df = calendar_df[calendar_df['listing_id'].isin(sampled_listings)]\n",
    "    calendar_df['date'] = pd.to_datetime(calendar_df['date'])\n",
    "    \n",
    "    # Clean price column\n",
    "    calendar_df['price_numeric'] = pd.to_numeric(\n",
    "        calendar_df['price'].replace('[\\$,]', '', regex=True),\n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Merge calendar with listings data\n",
    "    df = pd.merge(calendar_df, listings_cleaned, on='listing_id', how='left')\n",
    "    \n",
    "    print(f\"Total listings in sample: {len(df['listing_id'].unique())}\")\n",
    "    print(f\"Total records in sample: {len(df)}\")\n",
    "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_simple_arima(df, history_window=365, forecast_horizon=60):\n",
    "    \"\"\"\n",
    "    Train a simple ARIMA model on the market average price.\n",
    "    Uses the same time window as XGBoost for fair comparison.\n",
    "    \"\"\"\n",
    "    # Calculate market daily average price\n",
    "    market_prices = df.groupby('date')['price_numeric'].mean().reset_index()\n",
    "    market_prices = market_prices.set_index('date')\n",
    "    \n",
    "    # Calculate cutoff dates\n",
    "    latest_date = market_prices.index.max()\n",
    "    train_start = latest_date - timedelta(days=history_window)\n",
    "    validation_start = latest_date - timedelta(days=forecast_horizon)\n",
    "    \n",
    "    # Split data\n",
    "    train_data = market_prices[\n",
    "        (market_prices.index >= train_start) & \n",
    "        (market_prices.index < validation_start)\n",
    "    ]\n",
    "    \n",
    "    test_data = market_prices[market_prices.index >= validation_start]\n",
    "    \n",
    "    # Fit simple ARIMA model\n",
    "    try:\n",
    "        model = SARIMAX(\n",
    "            train_data,\n",
    "            order=(1, 0, 0),  # Simple AR(1) model given stable prices\n",
    "            enforce_stationarity=False\n",
    "        ).fit(disp=False)\n",
    "    except:\n",
    "        print(\"Falling back to even simpler model\")\n",
    "        model = SARIMAX(\n",
    "            train_data,\n",
    "            order=(1, 0, 0),\n",
    "            enforce_stationarity=True\n",
    "        ).fit(disp=False)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.forecast(len(test_data))\n",
    "    \n",
    "    return predictions, test_data\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    \"\"\"Calculate error metrics for predictions.\"\"\"\n",
    "    metrics = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def analyze_price_stability(df):\n",
    "    \"\"\"Analyze price stability across listings.\"\"\"\n",
    "    price_changes = df.groupby('listing_id')['price_numeric'].agg([\n",
    "        ('unique_prices', 'nunique'),\n",
    "        ('mean_price', 'mean'),\n",
    "        ('std_price', 'std'),\n",
    "        ('min_price', 'min'),\n",
    "        ('max_price', 'max')\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        'constant_price_listings': (price_changes['unique_prices'] == 1).sum(),\n",
    "        'avg_unique_prices': price_changes['unique_prices'].mean(),\n",
    "        'max_unique_prices': price_changes['unique_prices'].max(),\n",
    "        'avg_price_std': price_changes['std_price'].mean(),\n",
    "        'price_range': price_changes['max_price'].max() - price_changes['min_price'].min()\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    calendar_path = r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Merged_Data\\paris_merged_calendar.csv\"\n",
    "    listings_path = r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\listings.csv\"\n",
    "    \n",
    "    print(\"Loading and preparing data...\")\n",
    "    df = load_and_prepare_data(calendar_path, listings_path, n_listings=500)\n",
    "    \n",
    "    print(\"\\nAnalyzing price stability...\")\n",
    "    stability_metrics = analyze_price_stability(df)\n",
    "    print(\"\\nPrice Stability Analysis:\")\n",
    "    for metric, value in stability_metrics.items():\n",
    "        print(f\"{metric}: {value:.2f}\")\n",
    "    \n",
    "    print(\"\\nTraining ARIMA model...\")\n",
    "    model, results_df, test_data = train_simple_arima(\n",
    "        df,\n",
    "        history_window=365,\n",
    "        forecast_horizon=60\n",
    "    )\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    metrics, results_df, monthly_analysis = evaluate_predictions(\n",
    "        results_df['actual'],\n",
    "        results_df['predicted'],\n",
    "        results_df['date']\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nMonthly Error Analysis:\")\n",
    "    print(monthly_analysis)\n",
    "    \n",
    "    # Analysis by prediction month\n",
    "    first_month_mask = results_df['date'] < (results_df['date'].min() + timedelta(days=30))\n",
    "    second_month_mask = ~first_month_mask\n",
    "    \n",
    "    print(\"\\nPrediction Error by Month:\")\n",
    "    print(\"First Month:\")\n",
    "    print(f\"Mean Absolute Error: {results_df[first_month_mask]['abs_error'].mean():.2f}\")\n",
    "    print(f\"Mean Percentage Error: {results_df[first_month_mask]['pct_error'].mean():.2f}%\")\n",
    "    print(\"\\nSecond Month:\")\n",
    "    print(f\"Mean Absolute Error: {results_df[second_month_mask]['abs_error'].mean():.2f}\")\n",
    "    print(f\"Mean Percentage Error: {results_df[second_month_mask]['pct_error'].mean():.2f}%\")\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(\"\\nPrediction Statistics:\")\n",
    "    print(f\"Mean predicted price: ${results_df['predicted'].mean():.2f}\")\n",
    "    print(f\"Actual price range: ${results_df['actual'].min():.2f} - ${results_df['actual'].max():.2f}\")\n",
    "    print(f\"Predicted price range: ${results_df['predicted'].min():.2f} - ${results_df['predicted'].max():.2f}\")\n",
    "    \n",
    "    # Error distribution\n",
    "    percentiles = [25, 50, 75, 90]\n",
    "    print(\"\\nError Distribution:\")\n",
    "    for p in percentiles:\n",
    "        print(f\"{p}th percentile of absolute error: ${np.percentile(results_df['abs_error'], p):.2f}\")\n",
    "    \n",
    "    # Sample size analysis\n",
    "    print(\"\\nSample Size Analysis:\")\n",
    "    print(f\"Average daily listings: {results_df['sample_size'].mean():.1f}\")\n",
    "    print(f\"Min daily listings: {results_df['sample_size'].min():.0f}\")\n",
    "    print(f\"Max daily listings: {results_df['sample_size'].max():.0f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Total listings in sample: 500\n",
      "Total records in sample: 332673\n",
      "Date range: 2023-06-07 00:00:00 to 2025-09-12 00:00:00\n",
      "\n",
      "Analyzing price stability...\n",
      "\n",
      "Price Stability Analysis:\n",
      "constant_price_listings: 262.00\n",
      "avg_unique_prices: 4.80\n",
      "max_unique_prices: 105.00\n",
      "avg_price_std: 28.86\n",
      "price_range: 9989.00\n",
      "\n",
      "Training ARIMA model...\n",
      "\n",
      "Model Performance Metrics:\n",
      "RMSE: 21.3673\n",
      "MAE: 7.5328\n",
      "R2: -0.0266\n",
      "\n",
      "Monthly Error Analysis:\n",
      "                actual              predicted            abs_error             \\\n",
      "                  mean        std        mean       std       mean        std   \n",
      "date                                                                            \n",
      "2025-07-31  279.066000   0.000000  278.891978  0.097770   0.174022   0.097770   \n",
      "2025-08-31  279.066000   0.000000  278.443677  0.166246   0.622323   0.166246   \n",
      "2025-09-30  291.909911  48.183657  278.050794  0.065833  36.423028  32.914569   \n",
      "\n",
      "            pct_error             \n",
      "                 mean        std  \n",
      "date                              \n",
      "2025-07-31   0.062359   0.035035  \n",
      "2025-08-31   0.223002   0.059572  \n",
      "2025-09-30  12.834399  12.744388  \n",
      "\n",
      "Prediction Error by Month:\n",
      "First Month:\n",
      "Mean Absolute Error: 0.28\n",
      "Mean Percentage Error: 0.10%\n",
      "\n",
      "Second Month:\n",
      "Mean Absolute Error: 14.55\n",
      "Mean Percentage Error: 5.13%\n",
      "\n",
      "Prediction Statistics:\n",
      "Mean predicted price: $278.50\n",
      "Actual price range: $200.66 - $353.91\n",
      "Predicted price range: $277.95 - $279.05\n",
      "\n",
      "Error Distribution:\n",
      "25th percentile of absolute error: $0.29\n",
      "50th percentile of absolute error: $0.57\n",
      "75th percentile of absolute error: $0.84\n",
      "90th percentile of absolute error: $35.74\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_and_prepare_data(calendar_path, listings_path, n_listings=500):\n",
    "    \"\"\"Load and prepare the data with basic cleaning and sampling.\"\"\"\n",
    "    # Load listings first to get the sample\n",
    "    listings_df = pd.read_csv(listings_path)\n",
    "    sampled_listings = listings_df['id'].sample(n=n_listings, random_state=42)\n",
    "    \n",
    "    # Clean and prepare listings data\n",
    "    listings_cleaned = listings_df[listings_df['id'].isin(sampled_listings)][\n",
    "        ['id', 'neighbourhood_cleansed']\n",
    "    ]\n",
    "    listings_cleaned = listings_cleaned.rename(columns={'id': 'listing_id'})\n",
    "    \n",
    "    # Load and filter calendar data\n",
    "    calendar_df = pd.read_csv(calendar_path)\n",
    "    calendar_df = calendar_df[calendar_df['listing_id'].isin(sampled_listings)]\n",
    "    calendar_df['date'] = pd.to_datetime(calendar_df['date'])\n",
    "    \n",
    "    # Clean price column\n",
    "    calendar_df['price_numeric'] = pd.to_numeric(\n",
    "        calendar_df['price'].replace('[\\$,]', '', regex=True),\n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Merge calendar with listings data\n",
    "    df = pd.merge(calendar_df, listings_cleaned, on='listing_id', how='left')\n",
    "    \n",
    "    print(f\"Total listings in sample: {len(df['listing_id'].unique())}\")\n",
    "    print(f\"Total records in sample: {len(df)}\")\n",
    "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_simple_arima(df, history_window=365, forecast_horizon=60):\n",
    "    \"\"\"\n",
    "    Train a simple ARIMA model on the market average price.\n",
    "    Uses the same time window as XGBoost for fair comparison.\n",
    "    \"\"\"\n",
    "    # Calculate market daily average price and sample size\n",
    "    market_data = df.groupby('date').agg({\n",
    "        'price_numeric': 'mean',\n",
    "        'listing_id': 'count'\n",
    "    }).rename(columns={'listing_id': 'sample_size'})\n",
    "    \n",
    "    # Calculate cutoff dates\n",
    "    latest_date = market_data.index.max()\n",
    "    train_start = latest_date - timedelta(days=history_window)\n",
    "    validation_start = latest_date - timedelta(days=forecast_horizon)\n",
    "    \n",
    "    # Split data\n",
    "    train_data = market_data[\n",
    "        (market_data.index >= train_start) & \n",
    "        (market_data.index < validation_start)\n",
    "    ]\n",
    "    \n",
    "    test_data = market_data[market_data.index >= validation_start]\n",
    "    \n",
    "    # Fit simple ARIMA model\n",
    "    try:\n",
    "        model = SARIMAX(\n",
    "            train_data['price_numeric'],\n",
    "            order=(1, 0, 0),  # Simple AR(1) model given stable prices\n",
    "            enforce_stationarity=False\n",
    "        ).fit(disp=False)\n",
    "    except:\n",
    "        print(\"Falling back to even simpler model\")\n",
    "        model = SARIMAX(\n",
    "            train_data['price_numeric'],\n",
    "            order=(1, 0, 0),\n",
    "            enforce_stationarity=True\n",
    "        ).fit(disp=False)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.forecast(len(test_data))\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': test_data.index,\n",
    "        'actual': test_data['price_numeric'],\n",
    "        'predicted': predictions,\n",
    "        'sample_size': test_data['sample_size']\n",
    "    })\n",
    "    \n",
    "    # Calculate errors\n",
    "    results_df['abs_error'] = np.abs(results_df['actual'] - results_df['predicted'])\n",
    "    results_df['pct_error'] = np.abs((results_df['actual'] - results_df['predicted']) / \n",
    "                                    results_df['actual']) * 100\n",
    "    \n",
    "    return model, results_df\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, dates):\n",
    "    \"\"\"Calculate comprehensive error metrics for predictions.\"\"\"\n",
    "    # Basic metrics\n",
    "    metrics = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'actual': y_true,\n",
    "        'predicted': y_pred,\n",
    "        'abs_error': np.abs(y_true - y_pred),\n",
    "        'pct_error': np.abs((y_true - y_pred) / y_true) * 100\n",
    "    })\n",
    "    \n",
    "    # Monthly analysis\n",
    "    monthly_analysis = results_df.set_index('date').resample('ME').agg({\n",
    "        'actual': ['mean', 'std'],\n",
    "        'predicted': ['mean', 'std'],\n",
    "        'abs_error': ['mean', 'std'],\n",
    "        'pct_error': ['mean', 'std']\n",
    "    })\n",
    "    \n",
    "    return metrics, results_df, monthly_analysis\n",
    "\n",
    "def analyze_price_stability(df):\n",
    "    \"\"\"Analyze price stability across listings.\"\"\"\n",
    "    price_changes = df.groupby('listing_id')['price_numeric'].agg([\n",
    "        ('unique_prices', 'nunique'),\n",
    "        ('mean_price', 'mean'),\n",
    "        ('std_price', 'std'),\n",
    "        ('min_price', 'min'),\n",
    "        ('max_price', 'max')\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        'constant_price_listings': (price_changes['unique_prices'] == 1).sum(),\n",
    "        'avg_unique_prices': price_changes['unique_prices'].mean(),\n",
    "        'max_unique_prices': price_changes['unique_prices'].max(),\n",
    "        'avg_price_std': price_changes['std_price'].mean(),\n",
    "        'price_range': price_changes['max_price'].max() - price_changes['min_price'].min()\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    calendar_path = r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Merged_Data\\paris_merged_calendar.csv\"\n",
    "    listings_path = r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\Data_Mor\\paris\\2024-09-06\\listings.csv\"\n",
    "    \n",
    "    print(\"Loading and preparing data...\")\n",
    "    df = load_and_prepare_data(calendar_path, listings_path, n_listings=500)\n",
    "    \n",
    "    print(\"\\nAnalyzing price stability...\")\n",
    "    stability_metrics = analyze_price_stability(df)\n",
    "    print(\"\\nPrice Stability Analysis:\")\n",
    "    for metric, value in stability_metrics.items():\n",
    "        print(f\"{metric}: {value:.2f}\")\n",
    "    \n",
    "    print(\"\\nTraining ARIMA model...\")\n",
    "    model, results_df = train_simple_arima(\n",
    "        df,\n",
    "        history_window=365,\n",
    "        forecast_horizon=60\n",
    "    )\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    metrics, results_df, monthly_analysis = evaluate_predictions(\n",
    "        results_df['actual'],\n",
    "        results_df['predicted'],\n",
    "        results_df['date']\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nMonthly Error Analysis:\")\n",
    "    print(monthly_analysis)\n",
    "    \n",
    "    # Analysis by prediction month\n",
    "    first_month_mask = results_df['date'] < (results_df['date'].min() + timedelta(days=30))\n",
    "    second_month_mask = ~first_month_mask\n",
    "    \n",
    "    print(\"\\nPrediction Error by Month:\")\n",
    "    print(\"First Month:\")\n",
    "    print(f\"Mean Absolute Error: {results_df[first_month_mask]['abs_error'].mean():.2f}\")\n",
    "    print(f\"Mean Percentage Error: {results_df[first_month_mask]['pct_error'].mean():.2f}%\")\n",
    "    print(\"\\nSecond Month:\")\n",
    "    print(f\"Mean Absolute Error: {results_df[second_month_mask]['abs_error'].mean():.2f}\")\n",
    "    print(f\"Mean Percentage Error: {results_df[second_month_mask]['pct_error'].mean():.2f}%\")\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(\"\\nPrediction Statistics:\")\n",
    "    print(f\"Mean predicted price: ${results_df['predicted'].mean():.2f}\")\n",
    "    print(f\"Actual price range: ${results_df['actual'].min():.2f} - ${results_df['actual'].max():.2f}\")\n",
    "    print(f\"Predicted price range: ${results_df['predicted'].min():.2f} - ${results_df['predicted'].max():.2f}\")\n",
    "    \n",
    "    # Error distribution\n",
    "    percentiles = [25, 50, 75, 90]\n",
    "    print(\"\\nError Distribution:\")\n",
    "    for p in percentiles:\n",
    "        print(f\"{p}th percentile of absolute error: ${np.percentile(results_df['abs_error'], p):.2f}\")\n",
    "    \n",
    "    # Sample size analysis\n",
    "    if 'sample_size' in results_df.columns:\n",
    "        print(\"\\nSample Size Analysis:\")\n",
    "        print(f\"Average daily listings: {results_df['sample_size'].mean():.1f}\")\n",
    "        print(f\"Min daily listings: {results_df['sample_size'].min():.0f}\")\n",
    "        print(f\"Max daily listings: {results_df['sample_size'].max():.0f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spatiotemporal_Analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
