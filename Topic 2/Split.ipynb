{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\De Ultieme Data\\top_price_changers_subset\\train.csv...\n",
      "Found 7864 unique listings.\n",
      "Creating 80-20 train-test split...\n",
      "Saving 6291 training listing IDs to .\\train_ids.txt...\n",
      "Saving 1573 test listing IDs to .\\test_ids.txt...\n",
      "Done!\n",
      "\n",
      "Summary:\n",
      "Training set: 6291 unique listings (80.0%)\n",
      "Test set: 1573 unique listings (20.0%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_listing_id_split_files(data_path, output_dir='.', test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Create two text files containing listing IDs for train (80%) and test (20%) sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_path : str\n",
    "        Path to the CSV file containing listing data with listing_id column\n",
    "    output_dir : str\n",
    "        Directory where train_ids.txt and test_ids.txt will be saved\n",
    "    test_size : float\n",
    "        Proportion of unique listings to be used as test set\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Error: File {data_path} does not exist!\")\n",
    "        return\n",
    "    \n",
    "    # Read the data\n",
    "    print(f\"Reading data from {data_path}...\")\n",
    "    try:\n",
    "        # First try reading with listing_id column\n",
    "        df = pd.read_csv(data_path)\n",
    "        id_column = 'listing_id' if 'listing_id' in df.columns else 'id'\n",
    "        \n",
    "        if id_column not in df.columns:\n",
    "            print(f\"Error: Neither 'listing_id' nor 'id' column found in the dataset!\")\n",
    "            return\n",
    "    except:\n",
    "        print(f\"Error reading {data_path}. Please check the file format.\")\n",
    "        return\n",
    "    \n",
    "    # Get unique listing IDs\n",
    "    unique_listings = df[id_column].unique()\n",
    "    print(f\"Found {len(unique_listings)} unique listings.\")\n",
    "    \n",
    "    # Split the unique listing IDs into train and test sets\n",
    "    print(f\"Creating {int((1-test_size)*100)}-{int(test_size*100)} train-test split...\")\n",
    "    train_listings, test_listings = train_test_split(\n",
    "        unique_listings, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Save the train and test listing IDs to text files\n",
    "    train_path = os.path.join(output_dir, 'train_ids.txt')\n",
    "    test_path = os.path.join(output_dir, 'test_ids.txt')\n",
    "    \n",
    "    # Save train listing IDs\n",
    "    print(f\"Saving {len(train_listings)} training listing IDs to {train_path}...\")\n",
    "    with open(train_path, 'w') as f:\n",
    "        for listing_id in train_listings:\n",
    "            f.write(f\"{listing_id}\\n\")\n",
    "    \n",
    "    # Save test listing IDs\n",
    "    print(f\"Saving {len(test_listings)} test listing IDs to {test_path}...\")\n",
    "    with open(test_path, 'w') as f:\n",
    "        for listing_id in test_listings:\n",
    "            f.write(f\"{listing_id}\\n\")\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return train_listings, test_listings\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # You can use either calendar.csv or listings.csv to get unique listing IDs\n",
    "    data_file = r\"C:\\Users\\matth\\OneDrive\\Documents\\KU Leuven\\Thesis\\De Ultieme Data\\top_price_changers_subset\\train.csv\"  # Update with your specific path\n",
    "    output_directory = \".\"  # Current directory\n",
    "    \n",
    "    train_listings, test_listings = create_listing_id_split_files(\n",
    "        data_path=data_file,\n",
    "        output_dir=output_directory,\n",
    "        test_size=0.2,  # 80-20 split\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Training set: {len(train_listings)} unique listings ({len(train_listings) / (len(train_listings) + len(test_listings)) * 100:.1f}%)\")\n",
    "    print(f\"Test set: {len(test_listings)} unique listings ({len(test_listings) / (len(train_listings) + len(test_listings)) * 100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spatiotemporal_Analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
